{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Supervised Learning\n",
    "## Project: Driving Behavior Prediction\n",
    "\n",
    "In this project, we will implement the machine learning algorithm to get a model able to detect the driver's mental state, whether: Focused, De-Focused or Drowsy, from his EEG brain signals readings, using a headset during driving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "In the next code cells, we will define some functions along with a few of the necessary Python libraries required for visualization and exploration of data, model training and testing, etc in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 'matplotlib.pyplot'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def distribution(data, value, transformed = False):\n",
    "    \"\"\"\n",
    "    Visualization code for displaying skewed distributions of features\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize = (11,5));\n",
    "\n",
    "    # Skewed feature plotting\n",
    "    for i, feature in enumerate([value]):\n",
    "        ax = fig.add_subplot(1, 1, i+1)\n",
    "        ax.hist(data[data.columns[feature-1]], bins = 25, color = '#00A0A0')\n",
    "        ax.set_title(\"'%s' Feature Distribution\"%(data.columns[feature-1]), fontsize = 14)\n",
    "        ax.set_xlabel(\"Value\")\n",
    "        ax.set_ylabel(\"Number of Records\")\n",
    "        ax.set_ylim((0, 500))\n",
    "        ax.set_yticks([0, 100, 200, 300, 400, 500])\n",
    "\n",
    "    # Plot aesthetics\n",
    "    if transformed:\n",
    "        fig.suptitle(\"Log-transformed Distributions of Continuous EEG Data Features\", \\\n",
    "            fontsize = 16, y = 1.03)\n",
    "    else:\n",
    "        fig.suptitle(\"Skewed Distributions of Continuous EEG Data Features\", \\\n",
    "            fontsize = 16, y = 1.03)\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 'accuracy_score'\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    # Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    score = accuracy_score(y_true, y_predict)\n",
    "    \n",
    "    # Return the score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 'make_scorer', 'SVC', 'GridSearchCV', and 'ShuffleSplit'\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def fit_model(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    cv_sets = ShuffleSplit(n_splits = 10, test_size = 0.20, random_state = 0)\n",
    "\n",
    "    # Create a linear discriminant analysis object\n",
    "    clf = SVC(kernel='rbf', class_weight='balanced')\n",
    "    \n",
    "    # Create a dictionary for the parameters\n",
    "    params = {'C': [1e3, 5e3, 1e4, 5e4, 1e5], 'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]}\n",
    "\n",
    "    # Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "    # Create the grid search cv object --> GridSearchCV()\n",
    "    # Make sure to include the right parameters in the object:\n",
    "    # (estimator, param_grid, scoring, cv) which have values 'clf', 'params', 'scoring_fnc', and 'cv_sets' respectively.\n",
    "    grid = GridSearchCV(clf, params, scoring=scoring_fnc, cv=cv_sets)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(X, y)\n",
    "\n",
    "    # Return the optimal model after fitting the data\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "\n",
    "In the next section, we will load the data and split it into features and target label. The data consists of 70 features and one target label the `state`. The feature vector for each data entry is about the five frequency bands values for each channel from the 14, concatenated in one vector performing the features. The state classes are represented in a numerical form, where: ***1*** is `Focused`, ***2*** is `De-Focused` and **3** is `Drowsy`.\n",
    "\n",
    "The dataset contains **510** data entries collected from different **34** EEG records of ***5*** participants (i.e. about 7 records for each participant on average). Each succesive **15** entry belong to one record, where each state class has **5** samples.\n",
    "\n",
    "The next code cell will display the first fifteen entries, which belong to the first record file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data: (510, 71)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta ch(1)</th>\n",
       "      <th>theta ch(1)</th>\n",
       "      <th>alpha ch(1)</th>\n",
       "      <th>beta ch(1)</th>\n",
       "      <th>gamma ch(1)</th>\n",
       "      <th>delta ch(2)</th>\n",
       "      <th>theta ch(2)</th>\n",
       "      <th>alpha ch(2)</th>\n",
       "      <th>beta ch(2)</th>\n",
       "      <th>gamma ch(2)</th>\n",
       "      <th>...</th>\n",
       "      <th>theta ch(13)</th>\n",
       "      <th>alpha ch(13)</th>\n",
       "      <th>beta ch(13)</th>\n",
       "      <th>gamma ch(13)</th>\n",
       "      <th>delta ch(14)</th>\n",
       "      <th>theta ch(14)</th>\n",
       "      <th>alpha ch(14)</th>\n",
       "      <th>beta ch(14)</th>\n",
       "      <th>gamma ch(14)</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.572947</td>\n",
       "      <td>0.284247</td>\n",
       "      <td>0.246387</td>\n",
       "      <td>1.166971</td>\n",
       "      <td>1.149049</td>\n",
       "      <td>3541.440612</td>\n",
       "      <td>35.999725</td>\n",
       "      <td>10.278806</td>\n",
       "      <td>14.119139</td>\n",
       "      <td>5.238184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145080</td>\n",
       "      <td>0.095880</td>\n",
       "      <td>0.278998</td>\n",
       "      <td>0.275061</td>\n",
       "      <td>882.886332</td>\n",
       "      <td>17.519078</td>\n",
       "      <td>9.432376</td>\n",
       "      <td>15.147043</td>\n",
       "      <td>5.821593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.429233</td>\n",
       "      <td>0.238602</td>\n",
       "      <td>0.252168</td>\n",
       "      <td>1.068175</td>\n",
       "      <td>1.159840</td>\n",
       "      <td>5411.470711</td>\n",
       "      <td>151.745579</td>\n",
       "      <td>10.770131</td>\n",
       "      <td>13.461449</td>\n",
       "      <td>5.515470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397978</td>\n",
       "      <td>0.093562</td>\n",
       "      <td>0.340707</td>\n",
       "      <td>0.312910</td>\n",
       "      <td>5503.528066</td>\n",
       "      <td>151.488443</td>\n",
       "      <td>10.554340</td>\n",
       "      <td>16.218259</td>\n",
       "      <td>6.645359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.407206</td>\n",
       "      <td>0.250608</td>\n",
       "      <td>0.270695</td>\n",
       "      <td>1.122825</td>\n",
       "      <td>1.164457</td>\n",
       "      <td>1923.459311</td>\n",
       "      <td>27.757026</td>\n",
       "      <td>10.330033</td>\n",
       "      <td>12.687345</td>\n",
       "      <td>4.412471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085161</td>\n",
       "      <td>0.063391</td>\n",
       "      <td>0.177088</td>\n",
       "      <td>0.175507</td>\n",
       "      <td>633.097970</td>\n",
       "      <td>15.431311</td>\n",
       "      <td>9.502504</td>\n",
       "      <td>14.413115</td>\n",
       "      <td>5.477437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.546453</td>\n",
       "      <td>0.241685</td>\n",
       "      <td>0.280362</td>\n",
       "      <td>1.137865</td>\n",
       "      <td>1.196406</td>\n",
       "      <td>4439.717244</td>\n",
       "      <td>77.442545</td>\n",
       "      <td>20.539788</td>\n",
       "      <td>19.605165</td>\n",
       "      <td>6.340742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147205</td>\n",
       "      <td>0.029482</td>\n",
       "      <td>0.145566</td>\n",
       "      <td>0.106374</td>\n",
       "      <td>4216.206768</td>\n",
       "      <td>46.123923</td>\n",
       "      <td>16.484015</td>\n",
       "      <td>17.312265</td>\n",
       "      <td>6.970426</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.444954</td>\n",
       "      <td>0.200428</td>\n",
       "      <td>0.254949</td>\n",
       "      <td>1.129726</td>\n",
       "      <td>1.194006</td>\n",
       "      <td>71234.345035</td>\n",
       "      <td>1240.070550</td>\n",
       "      <td>107.633892</td>\n",
       "      <td>38.436833</td>\n",
       "      <td>11.973087</td>\n",
       "      <td>...</td>\n",
       "      <td>6.557038</td>\n",
       "      <td>0.893655</td>\n",
       "      <td>0.378499</td>\n",
       "      <td>0.183685</td>\n",
       "      <td>78375.162620</td>\n",
       "      <td>1378.809431</td>\n",
       "      <td>123.644262</td>\n",
       "      <td>46.541710</td>\n",
       "      <td>14.101548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.266139</td>\n",
       "      <td>0.376277</td>\n",
       "      <td>0.210674</td>\n",
       "      <td>1.079059</td>\n",
       "      <td>1.133378</td>\n",
       "      <td>40471.241143</td>\n",
       "      <td>61.036090</td>\n",
       "      <td>14.452036</td>\n",
       "      <td>19.373414</td>\n",
       "      <td>11.324540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250090</td>\n",
       "      <td>0.097292</td>\n",
       "      <td>0.189574</td>\n",
       "      <td>0.172025</td>\n",
       "      <td>46509.144455</td>\n",
       "      <td>55.233378</td>\n",
       "      <td>17.100730</td>\n",
       "      <td>22.305623</td>\n",
       "      <td>14.107264</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.195754</td>\n",
       "      <td>0.405330</td>\n",
       "      <td>0.222020</td>\n",
       "      <td>1.061335</td>\n",
       "      <td>1.075114</td>\n",
       "      <td>7013.645250</td>\n",
       "      <td>43.707282</td>\n",
       "      <td>10.790249</td>\n",
       "      <td>13.163875</td>\n",
       "      <td>6.317268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056764</td>\n",
       "      <td>0.035444</td>\n",
       "      <td>0.088376</td>\n",
       "      <td>0.094955</td>\n",
       "      <td>7843.667194</td>\n",
       "      <td>37.345718</td>\n",
       "      <td>11.016696</td>\n",
       "      <td>15.494401</td>\n",
       "      <td>8.279327</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.182157</td>\n",
       "      <td>0.399722</td>\n",
       "      <td>0.201890</td>\n",
       "      <td>1.149534</td>\n",
       "      <td>1.126363</td>\n",
       "      <td>6818.960449</td>\n",
       "      <td>126.329278</td>\n",
       "      <td>11.581273</td>\n",
       "      <td>18.729675</td>\n",
       "      <td>8.411914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356097</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.154537</td>\n",
       "      <td>0.142348</td>\n",
       "      <td>7923.573110</td>\n",
       "      <td>139.076096</td>\n",
       "      <td>13.825262</td>\n",
       "      <td>21.639319</td>\n",
       "      <td>9.573691</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.166117</td>\n",
       "      <td>0.353679</td>\n",
       "      <td>0.215460</td>\n",
       "      <td>1.063283</td>\n",
       "      <td>1.153364</td>\n",
       "      <td>180.735988</td>\n",
       "      <td>24.804185</td>\n",
       "      <td>8.389364</td>\n",
       "      <td>11.530813</td>\n",
       "      <td>4.463484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057419</td>\n",
       "      <td>0.036699</td>\n",
       "      <td>0.105575</td>\n",
       "      <td>0.104321</td>\n",
       "      <td>78.655356</td>\n",
       "      <td>15.209409</td>\n",
       "      <td>9.685466</td>\n",
       "      <td>13.430976</td>\n",
       "      <td>4.847770</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.147261</td>\n",
       "      <td>0.411029</td>\n",
       "      <td>0.217897</td>\n",
       "      <td>1.073732</td>\n",
       "      <td>1.068933</td>\n",
       "      <td>45415.722572</td>\n",
       "      <td>156.073047</td>\n",
       "      <td>25.856097</td>\n",
       "      <td>24.804436</td>\n",
       "      <td>18.217311</td>\n",
       "      <td>...</td>\n",
       "      <td>1.079089</td>\n",
       "      <td>0.079519</td>\n",
       "      <td>0.187029</td>\n",
       "      <td>0.150347</td>\n",
       "      <td>54328.859063</td>\n",
       "      <td>186.305470</td>\n",
       "      <td>25.147339</td>\n",
       "      <td>30.134324</td>\n",
       "      <td>22.034817</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.279387</td>\n",
       "      <td>0.470095</td>\n",
       "      <td>0.271575</td>\n",
       "      <td>1.036917</td>\n",
       "      <td>0.827893</td>\n",
       "      <td>13298.685874</td>\n",
       "      <td>39.344269</td>\n",
       "      <td>9.328653</td>\n",
       "      <td>13.204686</td>\n",
       "      <td>4.363053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098892</td>\n",
       "      <td>0.053361</td>\n",
       "      <td>0.177785</td>\n",
       "      <td>0.182112</td>\n",
       "      <td>15737.743479</td>\n",
       "      <td>36.379383</td>\n",
       "      <td>10.223880</td>\n",
       "      <td>14.975793</td>\n",
       "      <td>5.259744</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.275577</td>\n",
       "      <td>0.516541</td>\n",
       "      <td>0.280070</td>\n",
       "      <td>1.048116</td>\n",
       "      <td>0.838895</td>\n",
       "      <td>99.678296</td>\n",
       "      <td>23.077530</td>\n",
       "      <td>7.328227</td>\n",
       "      <td>10.057563</td>\n",
       "      <td>3.934006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101156</td>\n",
       "      <td>0.064321</td>\n",
       "      <td>0.250923</td>\n",
       "      <td>0.202368</td>\n",
       "      <td>73.354204</td>\n",
       "      <td>14.028742</td>\n",
       "      <td>8.805788</td>\n",
       "      <td>12.753926</td>\n",
       "      <td>4.765577</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.269131</td>\n",
       "      <td>0.497217</td>\n",
       "      <td>0.259671</td>\n",
       "      <td>1.043312</td>\n",
       "      <td>0.810971</td>\n",
       "      <td>10250.407812</td>\n",
       "      <td>50.179330</td>\n",
       "      <td>11.663675</td>\n",
       "      <td>14.829173</td>\n",
       "      <td>4.907211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180551</td>\n",
       "      <td>0.092501</td>\n",
       "      <td>0.292440</td>\n",
       "      <td>0.236411</td>\n",
       "      <td>12061.546536</td>\n",
       "      <td>42.039739</td>\n",
       "      <td>11.455192</td>\n",
       "      <td>17.648044</td>\n",
       "      <td>5.969983</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.246102</td>\n",
       "      <td>0.511948</td>\n",
       "      <td>0.253228</td>\n",
       "      <td>1.036848</td>\n",
       "      <td>0.813437</td>\n",
       "      <td>17248.860640</td>\n",
       "      <td>96.228253</td>\n",
       "      <td>12.177757</td>\n",
       "      <td>14.728751</td>\n",
       "      <td>5.869104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223614</td>\n",
       "      <td>0.076634</td>\n",
       "      <td>0.256891</td>\n",
       "      <td>0.245798</td>\n",
       "      <td>20320.993091</td>\n",
       "      <td>89.464492</td>\n",
       "      <td>12.534446</td>\n",
       "      <td>18.195646</td>\n",
       "      <td>7.182905</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.260070</td>\n",
       "      <td>0.517050</td>\n",
       "      <td>0.263738</td>\n",
       "      <td>1.133445</td>\n",
       "      <td>0.831238</td>\n",
       "      <td>94.672762</td>\n",
       "      <td>30.523066</td>\n",
       "      <td>8.065386</td>\n",
       "      <td>10.680090</td>\n",
       "      <td>4.015674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099230</td>\n",
       "      <td>0.066325</td>\n",
       "      <td>0.232507</td>\n",
       "      <td>0.201984</td>\n",
       "      <td>70.853257</td>\n",
       "      <td>14.644873</td>\n",
       "      <td>7.587510</td>\n",
       "      <td>11.691215</td>\n",
       "      <td>4.457510</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    delta ch(1)  theta ch(1)  alpha ch(1)  beta ch(1)  gamma ch(1)  \\\n",
       "0      0.572947     0.284247     0.246387    1.166971     1.149049   \n",
       "1      0.429233     0.238602     0.252168    1.068175     1.159840   \n",
       "2      0.407206     0.250608     0.270695    1.122825     1.164457   \n",
       "3      0.546453     0.241685     0.280362    1.137865     1.196406   \n",
       "4      0.444954     0.200428     0.254949    1.129726     1.194006   \n",
       "5      0.266139     0.376277     0.210674    1.079059     1.133378   \n",
       "6      0.195754     0.405330     0.222020    1.061335     1.075114   \n",
       "7      0.182157     0.399722     0.201890    1.149534     1.126363   \n",
       "8      0.166117     0.353679     0.215460    1.063283     1.153364   \n",
       "9      0.147261     0.411029     0.217897    1.073732     1.068933   \n",
       "10     0.279387     0.470095     0.271575    1.036917     0.827893   \n",
       "11     0.275577     0.516541     0.280070    1.048116     0.838895   \n",
       "12     0.269131     0.497217     0.259671    1.043312     0.810971   \n",
       "13     0.246102     0.511948     0.253228    1.036848     0.813437   \n",
       "14     0.260070     0.517050     0.263738    1.133445     0.831238   \n",
       "\n",
       "     delta ch(2)  theta ch(2)  alpha ch(2)  beta ch(2)  gamma ch(2)  ...  \\\n",
       "0    3541.440612    35.999725    10.278806   14.119139     5.238184  ...   \n",
       "1    5411.470711   151.745579    10.770131   13.461449     5.515470  ...   \n",
       "2    1923.459311    27.757026    10.330033   12.687345     4.412471  ...   \n",
       "3    4439.717244    77.442545    20.539788   19.605165     6.340742  ...   \n",
       "4   71234.345035  1240.070550   107.633892   38.436833    11.973087  ...   \n",
       "5   40471.241143    61.036090    14.452036   19.373414    11.324540  ...   \n",
       "6    7013.645250    43.707282    10.790249   13.163875     6.317268  ...   \n",
       "7    6818.960449   126.329278    11.581273   18.729675     8.411914  ...   \n",
       "8     180.735988    24.804185     8.389364   11.530813     4.463484  ...   \n",
       "9   45415.722572   156.073047    25.856097   24.804436    18.217311  ...   \n",
       "10  13298.685874    39.344269     9.328653   13.204686     4.363053  ...   \n",
       "11     99.678296    23.077530     7.328227   10.057563     3.934006  ...   \n",
       "12  10250.407812    50.179330    11.663675   14.829173     4.907211  ...   \n",
       "13  17248.860640    96.228253    12.177757   14.728751     5.869104  ...   \n",
       "14     94.672762    30.523066     8.065386   10.680090     4.015674  ...   \n",
       "\n",
       "    theta ch(13)  alpha ch(13)  beta ch(13)  gamma ch(13)  delta ch(14)  \\\n",
       "0       0.145080      0.095880     0.278998      0.275061    882.886332   \n",
       "1       0.397978      0.093562     0.340707      0.312910   5503.528066   \n",
       "2       0.085161      0.063391     0.177088      0.175507    633.097970   \n",
       "3       0.147205      0.029482     0.145566      0.106374   4216.206768   \n",
       "4       6.557038      0.893655     0.378499      0.183685  78375.162620   \n",
       "5       0.250090      0.097292     0.189574      0.172025  46509.144455   \n",
       "6       0.056764      0.035444     0.088376      0.094955   7843.667194   \n",
       "7       0.356097      0.065461     0.154537      0.142348   7923.573110   \n",
       "8       0.057419      0.036699     0.105575      0.104321     78.655356   \n",
       "9       1.079089      0.079519     0.187029      0.150347  54328.859063   \n",
       "10      0.098892      0.053361     0.177785      0.182112  15737.743479   \n",
       "11      0.101156      0.064321     0.250923      0.202368     73.354204   \n",
       "12      0.180551      0.092501     0.292440      0.236411  12061.546536   \n",
       "13      0.223614      0.076634     0.256891      0.245798  20320.993091   \n",
       "14      0.099230      0.066325     0.232507      0.201984     70.853257   \n",
       "\n",
       "    theta ch(14)  alpha ch(14)  beta ch(14)  gamma ch(14)  state  \n",
       "0      17.519078      9.432376    15.147043      5.821593      1  \n",
       "1     151.488443     10.554340    16.218259      6.645359      1  \n",
       "2      15.431311      9.502504    14.413115      5.477437      1  \n",
       "3      46.123923     16.484015    17.312265      6.970426      1  \n",
       "4    1378.809431    123.644262    46.541710     14.101548      1  \n",
       "5      55.233378     17.100730    22.305623     14.107264      2  \n",
       "6      37.345718     11.016696    15.494401      8.279327      2  \n",
       "7     139.076096     13.825262    21.639319      9.573691      2  \n",
       "8      15.209409      9.685466    13.430976      4.847770      2  \n",
       "9     186.305470     25.147339    30.134324     22.034817      2  \n",
       "10     36.379383     10.223880    14.975793      5.259744      3  \n",
       "11     14.028742      8.805788    12.753926      4.765577      3  \n",
       "12     42.039739     11.455192    17.648044      5.969983      3  \n",
       "13     89.464492     12.534446    18.195646      7.182905      3  \n",
       "14     14.644873      7.587510    11.691215      4.457510      3  \n",
       "\n",
       "[15 rows x 71 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Allows the use of display() for DataFrames\n",
    "from IPython.display import display\n",
    "\n",
    "# Read the data.\n",
    "raw_data = pd.read_csv('data_set_file.csv')\n",
    "\n",
    "# Split the data into features and target label\n",
    "target_raw = raw_data[raw_data.columns[-1]]\n",
    "features_raw = raw_data.drop(raw_data.columns[-1], axis = 1)\n",
    "\n",
    "# Print data shape. \n",
    "print(\"The shape of the data: {}\".format(raw_data.shape))\n",
    "\n",
    "# Success - Display the first fifteen records\n",
    "display(raw_data.head(n=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Preparing the Data\n",
    "Before data can be used as input for machine learning algorithms, it often must be cleaned, formatted, and restructured — this is typically known as **preprocessing**. Fortunately, for this dataset, there are no invalid or missing entries we must deal with, however, there are some qualities about certain features that must be adjusted. This preprocessing can help tremendously with the outcome and predictive power of nearly all learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Skewed Continuous Features\n",
    "A dataset may sometimes contain at least one feature whose values tend to lie near a single number, but will also have a non-trivial number of vastly larger or smaller values than that single number. Algorithms can be sensitive to such distributions of values and can underperform if the range is not properly normalized. With our dataset for example, feature such as: `'delta ch(2)'`, fit this description. \n",
    "\n",
    "The code cell below will plot a histogram of this feature. Note the range of the values present and how they are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAF2CAYAAAD+y36TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcLFV9///Xm90FwQWVXFBQiUtMREUiwQXBREUjbiiJC7ihiUn0Z4yicUGjMZqIy9fEiCsuccMouESjbMbEDREBQQQVBFndWERA4PP745zmNk3PTM1we+5c7uv5eNSju06drjp1uqemPnVOnUpVIUmSJElDbLC2CyBJkiRp3WEAIUmSJGkwAwhJkiRJgxlASJIkSRrMAEKSJEnSYAYQkiRJkgYzgNA6J8ljknwlyQVJfpPkzCSfTvLwsTz7Jakkd1mbZV2qsfJvt0C+9/d8leSaJBclOTnJe5LsstT1TvnMMxZZ/vcnOWNsfru+3WctZj1LKddS9nElSbJBkrckObd/p59eIP/Nkrw0yXFJLklyeZJTk7x9lr//JAcm2X1K+nW++xursd/0XNOOY3nny/eYifXePMkBSb6V5OIkVyb5SZJPJNkrSRYo134T6/91kjOSfCrJE5Ms6f9+kh37d36rpXx+nvWeMUe9fHVNbmdse1v2/bjPLNYvrS82WtsFkBYjyd8AbwXeC/wz8GvgzsAjgd2BL6y90q01FwKP7u9vBtwVeArwf0n+qapeOpb3c8AuwLmLWP9+tGPFexfxmX+gfU+ztB/Ty7WUfVxJngA8H/hb4GvAz+fKmGRr4MvA7wBvB74KXAncA3gGsCtw7xmV81XA64AjJ9KX47tfSV4PHD4l/QcT8+8H3jkl36mjN0lWAV8CtgbeAbwSuAy4E7A38Gng/sA3BpRrb+BsYFPgDrRj5EeA/ZP8aVX9ZsA6xu1I+84/BPxikZ9dyBeBAyfSLl7D2xjZkrYfZwPHzWgb0o2eAYTWNS8CPl1VzxxLOxJ411KvrN0IXFlVXx+bPyLJO4A3AwckObaqPglQVRfSAo6ZSLJpVV1RVT+c1TYWMut9XAZ3769vqaprFsj7QdrJ5s5VddpY+lFJ/g3YaxYFnM/a/O7Xkh9N/P3N5acD8n0YuC2w00Q9HgO8L8lDgYsGluv4qjp9bP6DST4BfAJ4I/DXA9ezHH42sA5XrNGxb22XQ1ou6+sJl9ZdtwLOm7ZgoZOtJPdNcn6S/0yyWU/bqHf/+H6SK5Kck+RNo+U9z0lJ3j02v0WSq5OcPbH+/03y8bH5Bdfd890pyeeSXJbkwiRvpV01XLJqj5h/MXA+8IKxbV2ve0+SP0/ynSSXpnWBOjHJc/qyo4EHA7uOdS04emJdD+rdK35FvzI6TzeWTZIclNb97LIkn81EV6O+zgMn0kbdRfZbRLnG93HjJK/t3SWu7K+vTbLxlG08J8lr0roQ/SrJZ5JsM1GeOetsPkkenuRraV3vLkrrenfXseVnsPpK7NXj+zxlXTsDewD/OBE8AO03UFWfHsu/xuogSfW3fz9W/wf2ZXN1XxtSrwt+92PpT0ny3bQuWz9L8sG0FplFry/J/ZJ8KcnP++/yR2kB2LJJcn/ab/p1cwVhVfXlqvr+UrfRLyQcBjw7yU3Htv3qtC5wF/W6PLKXZ7R8P+B9ffa0se98u778r/rv+hf9u/16kkcutZzTJHlcX+9lfRufSHKHiTz79LJf2P82v5Nk37Hl2wE/7rPvGtuP/fryM5K8f8q2r/M7SusCVUnumeSLSS4Fxo/9Q8q6pGOItFIYQGhd801g3yR/l+R3h34oyZ8ARwOfAvauqsv7og8BLwf+g9bE/3rgmbQrgSNH0rpHjewGXAGsGpUhyc2A+wFHjeVbcN1JNqF1Wbg38Dxat5zt++dukKq6EjgC2DnJ1NbGJA/o5TwGeAyt28O7aM38AH8JfAc4gdYtaJeeNu7DtH/KTwAOWKBYLwV2AJ5O29/7Av89fhI70JByjTukl+0DwKNoJ0Mv6enTyngXWheg5/d1j39nC9XZVGn36HwOuBR4EvAXwD2Br6Z1XQF4LK2rC2P79bk5VvnQ/jqt+8w0a6wO+jy9rKNyvpv5LbTOwZLsT2t9OQV4HG2/HgYck+Tmi1zXzWldaK6m/f3tCbyG4S30G6RdLBifNpy+qevlG9/GHv31s4sp/xJ8nnaBYqextFW0FsvH0OrgAuArSf6gL/8c8Nr+fm9Wf+ejboLb0b7/vWm/7WOBzyZ5xMAyTaubjC18LvBJ4GTaceY5tL+dY5JsPraeOwGHAk/u+/IZ4N398/TyPq6/fz0L/40t5DDaceDRtPobVNalHkOkFaWqnJzWmQn4XdpJY/XpZ7R+vX8ykW+/vvwutH8mVwKvmcjzwJ7naRPpT+7pO/b5x/b5O/b5t9BO2k4DntPTHt7z3G2R6352n7//WJ4NgO/19O0WqI/3A2fPs/z1fT23m6iX7fr8i4BfLLCNo4GvTkkfrevNc5TrjLH57Xrek4ENxtJ37enPHEsr4MCJ9Y0+v98iyjXax3vOsc6X9/Q/mNjGMRP5XtTTf2donc1Rj8f238xGY2nbA78FDhpLey29EWmB9b2jl2vTAXnXaB2MfU+vXcR3P3Sd8373wIa0lrWjJvI9oOf7m0Wub6fxOljE9zlaz7Tp0om8c+Ur4DbzfZ+048FGY9MGC5Rrv76eu8yx/GF9+ZPmWL5h386pwFuHrndKef8bOGxAPZ4xR708tC+/Oa3b1nun1P+VwAsWKMe7gO9O+d6eNUdZ3j8l/Tq/I1orYQHPn8g3qKws8Rji5LSSJlsgtE6pqh/QrtY/mHYD5/G0E/wvJpl21f4FtBOa51fVKyeWPZx2UP/kxBXB/+7LH9RfjwGuYXUrxO60VokjJ9LOrdXdC4auexfgrBrr/1utK9a1zeE30OgqXs2x/FvALZN8KMmjkizlCtinFpH30BrralZV/0u7mfF6I0atQaO6/tBE+mj+wRPpk1cjT+yvoy4Ii66z3kJ1H+BjVXXVKL2qfgz875QyrGlrug6WYk2t8660+wSu03pRVV8FzmTxdXka8CvgnWndorZd5OdfS2t9HJ8eOCXfe6fku1/fNqz+W530b7QgczS9ZpHlm3S9Y0KShyY5KsnPgav6dn6XVtcLr7B1D/1skvPHPv/HQz8P/BfXr5fRjeK7ALcAPjxxLD0b+D6rf9sk2SHJR5L8lNX19axFlGOxJo99Q8u6Jo670lplAKF1TlVdXVVfqaqXV9VDac3WJwKvSnLLiez7AD+lNSlPui2wCa1Lyfg/6Av68lv37f0C+C7wkCS3oV3NPapPu/W8D+G63ZcGrZt2A+z5U8o2LW0ptqUFMlNHTamqY2jN59vS/hlemOTLY10XhljMaEdz7euqKelrymjYyclynjexfGSyrkY3Rm4GS66zW9JO3KbV1XlTyjDEWf31jgPyrtE6WKI1tc659gWWUJdVdRHt7/cc2sn6T9Lue3r8wFWcWVXHTkzfmZLv3Cn5jh0LKEff52RA9Y+sPqleE0YB0rkAacOZfp52rHombZSn+9GOeQt+Nz3gOoJW738N/FH//BeGfL77xZR6uaQvu21//TLXPZb+Fvh9+rG0d0X7EnAvWpe2B/ZyvJcbeE/ZPCZ/g4PKuoaOu9Ja5ShMWudV1TlpNzm/lda//ptjix8PHAwcnWT3qhq/AfvnwOVMv1oI7YRi5Cha396H9M+dQPvncdsko6Eyx4doHLruc4Hfm7L8dnN8brB+f8VDga+PX/WeVFWHAof2f8C7AW8AvpBkm1p4FCCYu3Vjmmn7dTtaS9LIFbTga9ytWbrRievtgfGbU2/fX+ccJnUuS6izX9Lq6fZTlt1+KWWgnaS8DvhT4E0L5F3jdTAjQ7778X2ZdHtaV7HFrI+qOh54fL9avBPtfo2PJ7lXVZ00sOw31Gg43EfR+9P3sv0E+AlA5n8ExFCPpB2bvt3nH09rNXhcVf12lKlfjPnV9T9+PQ8HtgCeWFXXDiyRsZu0b6DRb3M/WtfOSaNAYxdaMP3A3ho1KsdiznMuZ+L3kvmfezF57Bta1jVx3JXWKlsgtE6Zp3vB3frr5AhNP6UdnDegDW05PkrL6ArZFnNcGZwMIFbRbog7upoLaP8kXk3rN3zkEtb9NWDbXHfEkw2AJw6pj7n0GxDfSLsi9uYFsgNQVZdW1WdpgdDWrD7RugK4yQ0pz5gnZGy43R58bUOrh5Ezaa0846aN6DK0XMf0130m0p/cX78yYB1TzVNnk/l+TTth23v8Btskd6RdsT1m2ucW2PY3aVd+X5Y5HhiXZDSM6yzq4ErW3O9iZMh3fyqt1eo6+5Lkj2gnkON1OfS3BEBVXdW7E76Cdsy4+1x517Sq+hrwP7SRre48i20keRztht9/r6rLevJNaTeQj3dp2p3rt4SMWowmv/NRoDAefPwu7f6mNeH/aCfed5njWDp6jsa0ctyS6w9lPNd+wPTfy6NmUNZrDT2GSCuNLRBa15yU5Chas++Paf1N9wSeC3y8X627jqo6N8lutJOto5M8pKrOqaqjk3yEdhXoIFrLxTW0G972BF7S77mAdoJ1NW2klOeNrf4o4K+An1TVj8a2OXTdo5Fx/jPJy2hdnJ7b92uoTcYCkJuy+kFyu9Bucp3zScZJXkNrATiK1iqyDfA3tDHkR89SOBn4yyRPol29vmTaP8KBNgc+neSdwFa0m7xPo40MNPJR4OVJ/h74Oq0V58+mrGtQuarqe/27OLBfjfw/Wt28AvhIVZ2wmB0YWGfTvIJ2H8Bn04YIvTkt+LyIhVsQ5vJUWkvEt5L8P1Y/SO5utNGONqbdyLpG66A7GXhkki/QWljOmQi6l2LB776qrk7ySto9Cx+i3cexitYacxqrhxsdtL4kjwL2pz2k7ce0hzH+De1EcDywncudxi8AjPlB7/44smqOfGdW1agrzJ/TjlPH9t/I/9AelrkV8Cc9zyXXX8VUO/Yul5vQgoFH0brNfInWwjLyBfq9YkneR7v34RW0iy/jTu6vz0tyCO1E/QTa7+8q4ANJ3kQ7CX41rdXkBl+krKqLk/wd8K9JtqLdL3ER7Tt/MO2Czn/QftMX93yvon2PL6cNtLHF2CrPp7UU7JPkBFr9/riqfk77vbw3yZtpo2Hdi9aasEbLegOOIdLKMeROayenlTLRTq4Pp10pupx28P8O7ZkHm4zl24+JEUNoV+NPpD0hdlVP24A2pOR3+/ou6u/fSGs9GN/2NxgbaamnjUZoev+Usg5aN+0ejs/Tnjh7Ia0r1nMYPgrTaNSSa2gnF6cA72FsZKcp9bJdn38kbQjLc2lX5s7qnx0fGef2vXyX9M8ePVcdT5TrjLH57XrevwQO6vt5Ge2EevuJz27W6+Dcvs2PATtz/VGYFirXdmN5N6bd7Hom7cTnzD6/8ZQyPmuiPLv19N2G1tk839fDaSelv+m/h8OAu07kGTQK01j+mwMvo/0d/LqX6dReh3eaRR30tF1prSqXMzZKzTzf/ZB1Dvrue96n0P6erqCdEH4Q2HqxvyVawP0xWvBwOe23+XngDxeo99F+zTU9YSzvfPleNLHezfv3+e1e5itpJ+OfAP50wO9hv4n1/6Z/15+iBRCZ8pm/7vv/G9oNvg+ljXJ29ES+V9ECi1GLxeg48kTaTcKX01pl95n8HcxT3jOADw3ItyfthPviXs7Tafc33GMsz+60v4Pf0C4q/A19xKSJdT2GFhD9duK3sAHt6d9n0o5PXwTuzNyjMG20lLJyA44hTk4rZUrVYrovS5IkSVqfeQ+EJEmSpMEMICRJkiQNZgAhSZIkaTADCEmSJEmDGUBIkiRJGswAQpIkSdJgBhCSJEmSBjOAkCRJkjSYAYQkSZKkwQwgJK3zkpyU5MBF5N8tSSW5zQyLNW272/Xt7jQg74FJ3rvI9X8zyeOWXkKN9Po/aUbrPiPJi8bmK8kTZrStme2HpPWXAYSkFS3J+xcTHCxxG/sluXSW21iMJLcFXgi8diztpUm+leTiJBcm+UySe0589B+ANyTZYOxz+yU5eoHt1ZTp+DW4S9c7aV4bel2M9u/qJL9KcmyS1/U6H/cvwIMHrnexAen9gH9bTNkHlGGu4HTwfkjSUAYQkrTyPAv4ZlX9aCxtN9pJ5x8BuwNXAV9OcquxPJ8HNgcesYRtPhvYemzaYwnrmLkkGyTZ8Aas4jLa/m0D/CHwFuDRwElJ7j7KVFWXVtXPb1BhJyTZpK/7wqq6bE2uey6z2A9JMoCQtE5JctskhyX5TZIzkzxjSp4tkhyc5IIklyQ5Zq5uQ0l2A94H3Gzs6vSBfdlT+lX/S/q6PpFk1QLlS5K/TXJakiuSnJ3k9RPZ7pjkS0kuS3Jykj+eWP7nwOHjCVX1sKp6X1WdVFUnAk8FtgJ2HctzNS2I+LP5yjiHX1XVeWPTtSedSVYl+WiSX/bpc0l2GFt+5/6dnJfk10mOS/KoseVHA3cE/nlUxz39ei0/k1fzR3mS7Nm74lwJ3L0ve3qvv8uT/CDJ/zfe+jKH6vt3blWdWlUfAnYBfgX8+1g5rtP1J8nvJzmitwBdkuS7SR6SZDvgqJ7twl7294/2O8k7kvxLkguB/+3p01pjbt/r9bL+u37K2Lanti7kul2fftxfv9XTj55jPzZI8ookZ/Xf54lJ9pqyrccv8BuVtB4zgJC0rnk/cBfgocBjgKcB240WJgnwOWAV8Cjg3sBXgCOTbD1lff8HvIDVV6a3pnX7ANgEeBVwr76u2wAfWaB8/wi8Ang98HvA3sBZE3leB7ytr/dbwEeT3LyX/1bAPYBjF9jO5rRj+C8n0r/JGuyykuSmtBPky/t6dwHOpbV+3LRnuznwX8Af0/bpk8B/JrlbX/444GzgNayu48XYDHg58Bxa3ZyZ5Nm0un4lLaD4W+AlwF8udh+r6lJa8PCgJFvNke0/aPu9M+03dSCtTs4CHt/z/B5t354/9rmnAAEeSPutzuXVtKBxR+Bg4ANzBb1z2Lm/PryXYa57YZ4P/B2trn4f+BTtu9pxIt+cv1FJoqqcnJyc1okJ+F2ggF3H0u4IXA0c2Od3By4FbjLx2eOBF/f3u/X13KbP7wdcOmD7d+uf22aO5TennVQ+d47l2/XPP2csbVVPe0Cf37HPb79AWT4OfAfYcCL90cA1wEaLqNcCftPrbTQ9uS97BnAakLH8GwI/B544zzq/Drx8bP4M4EUTea5X73N8NwXcdyLfT4CnTqS9ADh5njLN+T3TTrwL2LnPHwicNLb8YmDfOT57nTKPpR8NnDAl/3Xqon/2XRN5vgx8aOJ3s9OU7+0JC+SZ3I+fAq+cUs7Jbc35G3VycnLaCElad9yddnL8zVFCVZ2Z5JyxPPcFbkrrTjL+2c2AOy9mY0nuQ2uB2BG4Fe1KMsAdaFfUJ90D2BQ4YoFVnzD2flT20U28N+mvl89TroOAB9BO6K6eWPybXs7NaIHAUH8HfGFs/vz+el9ge+CSifq8Kb0+k9yMVk+Pol393rhvf3w/b4iraAEgfXtbAdsC70zyjrF8G7H6O1qs0edqjuUHAe9Osi/t+/1kVX1/wHq/PXD7X5sy/8iBnx0kyS2A36F3pRrzVWDPibT5fqOS1nMGEJLWJUNODjegnfw+cMqyiwdvqJ0Uf5F2JfipwAW0Lkz/Q+vatNTyAfx29Kaqqp+Yj7qU/qy/3pLWZWayXG8G9gEeUte9yXrkVsDl1brlLMZ5VXX6lPQNaCfv+0xZ9ov++i+0K/gvorVWXAZ8gLnraeQarl9nG0/Jd8VEoDSqq+fSuqCtCfegBQ9nTFtYVQcm+TDtBvWHAa9K8tyqWmio3V+vgbJd01+vrask0+ppqGlB0mTafL9RSes5AwhJ65JTaCcx96OfOCa5A+2q6shxwO2Aa+Y4wZ7mSlq3nHF3owUML6uqH/dtLfSMhZOBK2gjGJ02cNuTfkgLdO7R13etJG+lncjvNs/V73vS6mBNOY52U/bPqupXc+R5APCBqvpkL+eotecHY3mm1fGFwE2T3KKqRsHdZF/866mq85P8FLhzVX1g+K5M1/v2Pxc4pqounGe7p9G+17f1lo9nAe+l7Rtcf/8W4/59XePzp/T3ozKN3zsyWU8LlqGqLu6tdQ8Ajhxb9AAmfmuSNB+vJkhaZ1TVqbRuNu9Msku/8fP9tG47I1+mddE4LMkjkmzf8746ybRWCWhXnTdL8sdJbtNvDv4JLRj4qyR3SvJI2nMW5ivfJcBbgdf3EYLunGTnJH+xiH28pu/DA8bTk/wr8HTayfwvk9y+T5M3tj6Q63ZFuqE+TGvROSzJg3t9PijJm7J6JKYfAI9Ncp8kvw98iNaFadwZwAPTRnQaPS/hG7Qr9K9Pcpckj2f4TdAHAi/uIy/dNck9kzwtyUsX+FzG6u6ufbSjrwFbzLXtJDdJ8q9pI0Rtl+QPue5J95m0K/iPTLLVEm82flySZyfZoe/DHrQhZqmq39DuKXlJkt9L8kesvtF/5ALa38HDktwuyRZzbOefgRcl+bMkv5vkNbTfzJuWUGZJ6ykDCEnrmv1oQ1YeCXyGNjrOGaOFVVW0/txHAu8CTqXdcHxXVvflvo6q+j/aKDwfoV3tfXG/Er0vbaSnk2l9/F84oHwvBd5AG4npFNqIRNssag/bKDxPynWfd/CXtJGXjqB1bRpN4080XkV7TsT7Frm9OVV7XsGDgB8BnwC+DxxC62I1GgHqhbQT2P+hjcb09f5+3Ctp9y38kH5Fvap+ATyZNnrTicD+tHobUq53027wfirw3b69/Vk9nOlcbkqrt3No99K8kPY7umdVnTLHZ66m7e8htN/Tp2hBxwt7WX5K+328jhZsvX3IPkw4kDaa0wnAXwBPr6pvjS0fDVf8LeCdtFGprlVVVwF/Q2sVOQc4bI7tvI0WRLwROAl4LPD4qlqjDw6UdOOW9r9WkrSSJPka8G9V9cFFfOafgS2qav/ZlUyStL6zBUKSVqbnsPhj9AUMvIIvSdJSzbQFIskZwCW05t+rqmqn/pCkj9HGmj6DNo74L/vDn95K63pwGbBfVa3JGwElSZIk3UDL0QLxkKrasapGT9Q8ADiiqnag9eU9oKc/AtihT/sD77jemiRJkiStVWujC9NetBvR6K+PGUv/QDVfB7ZMsvW0FUiSJElaO2b9HIgC/jtJAe+sqoOB21XVuQBVdW6S0ZMtVwFnjX327J52nQcpJdmf1kLBzW52s/ve7W53m/EuSJIkSTd+3/72t39WVVstlG/WAcSuVXVODxK+lGSuBx/B9Ce4Xu8GjR6EHAyw00471bHHHrtmSrpEOeSQhTOtIbXvvsu2LUmSJK1fkpw5JN9MuzBV1Tn99QLauNk7A+ePuib11wt69rNpY4SPbMMcY7ZLkiRJWjtmFkAkuVmSzUfvgT+hPbTmcNrDmeivo4fdHA48Lc39gYtGXZ0kSZIkrQyz7MJ0O+BTbXRWNgL+o6q+kORbwMeTPBP4CbB3z/952hCup9OGcX36DMsmSZIkaQlmFkBU1Y+Ae01J/zmwx5T0Ap43q/JIkiRJuuF8ErUkSZKkwQwgJEmSJA1mACFJkiRpMAMISZIkSYMZQEiSJEkazABCkiRJ0mAGEJIkSZIGM4CQJEmSNJgBhCRJkqTBDCAkSZIkDWYAIUmSJGkwAwhJkiRJgxlASJIkSRrMAEKSJEnSYAYQkiRJkgYzgJAkSZI0mAGEJEmSpMEMICRJkiQNZgAhSZIkaTADCEmSJEmDGUBIkiRJGswAQpIkSdJgBhCSJEmSBjOAkCRJkjSYAYQkSZKkwQwgJEmSJA1mACFJkiRpMAMISZIkSYMZQEiSJEkazABCkiRJ0mAGEJIkSZIGM4CQJEmSNJgBhCRJkqTBDCAkSZIkDWYAIUmSJGkwAwhJkiRJgxlASJIkSRrMAEKSJEnSYAYQkiRJkgYzgJAkSZI0mAGEJEmSpMEMICRJkiQNZgAhSZIkaTADCEmSJEmDGUBIkiRJGswAQpIkSdJgBhCSJEmSBjOAkCRJkjSYAYQkSZKkwWYeQCTZMMl3kny2z2+f5BtJTkvysSSb9PRN+/zpffl2sy6bJEmSpMVZjhaI5wOnjM2/AXhzVe0A/BJ4Zk9/JvDLqroL8OaeT5IkSdIKMtMAIsk2wCOBd/f5ALsDh/YshwCP6e/36vP05Xv0/JIkSZJWiFm3QLwFeDFwTZ+/NfCrqrqqz58NrOrvVwFnAfTlF/X815Fk/yTHJjn2wgsvnGXZJUmSJE2YWQCR5FHABVX17fHkKVlrwLLVCVUHV9VOVbXTVltttQZKKkmSJGmojWa47l2BRyfZE9gMuAWtRWLLJBv1VoZtgHN6/rOBbYGzk2wEbAH8YoblkyRJkrRIM2uBqKqXVtU2VbUdsA9wZFU9GTgKeELPti9wWH9/eJ+nLz+yqq7XAiFJkiRp7Vkbz4F4CfDCJKfT7nF4T09/D3Drnv5C4IC1UDZJkiRJ85hlF6ZrVdXRwNH9/Y+AnafkuRzYeznKI0mSJGlpfBK1JEmSpMEMICRJkiQNZgAhSZIkaTADCEmSJEmDGUBIkiRJGswAQpIkSdJgBhCSJEmSBjOAkCRJkjSYAYQkSZKkwQwgJEmSJA1mACFJkiRpMAMISZIkSYMZQEiSJEkazABCkiRJ0mAGEJIkSZIGM4CQJEmSNJgBhCRJkqTBDCAkSZIkDWYAIUmSJGkwAwhJkiRJgxlASJIkSRrMAEKSJEnSYAYQkiRJkgYzgJAkSZI0mAGEJEmSpMEMICRJkiQNZgAhSZIkaTADCEmSJEmDGUBIkiRJGswAQpIkSdJgBhCSJEmSBjOAkCRJkjSYAYQkSZKkwQwgJEmSJA1mACFJkiRpsAUDiCS7JrlZf/+UJAcluePsiyZJkiRppRnSAvEO4LIk9wJeDJwJfGCmpZIkSZK0Ig0JIK6qqgL2At5aVW8FNp9tsSRJkiStRBsNyHNJkpcCTwEelGRDYOPZFkuSJEnSSjSkBeJJwBXAM6vqPGAV8M8zLZUkSZKkFWnBFogeNBw0Nv8TvAdCkiRJWi/NGUAkuQSouZZX1S1mUiJJkiRJK9YBGKOLAAAV2UlEQVScAURVbQ6Q5DXAecAHgQBPxpuoJUmSpPXSkHsgHlZV/1ZVl1TVxVX1DuDxsy6YJEmSpJVnSABxdZInJ9kwyQZJngxcPeuCSZIkSVp5hgQQfw48ETi/T3v3NEmSJEnrmXlHYerPfHhsVe21TOWRJEmStILN2wJRVVfTnkAtSZIkSYOeRP2/Sd4OfAz49Sixqo6bWakkSZIkrUhDAog/6q+vGUsrYPf5PpRkM+ArwKZ9O4dW1auSbA98FLgVcBzw1Kq6MsmmtAfU3Rf4OfCkqjpjEfsiSZIkacaGPIn6IUtc9xXA7lV1aZKNga8m+S/ghcCbq+qjSf4deCbwjv76y6q6S5J9gDcAT1ritiVJkiTNwIKjMCXZIslBSY7t05uSbLHQ56q5tM9u3KdRy8WhPf0Q4DH9/V59nr58jyRZxL5IkiRJmrEhw7i+F7iENpTrE4GLgfcNWXl/dsTxwAXAl4AfAr+qqqt6lrOBVf39KuAsgL78IuDWw3ZDkiRJ0nIYcg/Enatq/MnTr+5BwYL6KE47JtkS+BRw92nZ+uu01oaaTEiyP7A/wB3ucIchxZAkSZK0hgxpgfhNkgeMZpLsCvxmMRupql8BRwP3B7ZMMgpctgHO6e/PBrbt29gI2AL4xZR1HVxVO1XVTltttdViiiFJkiTpBhoSQPwF8K9JzkhyBvB24LkLfSjJVr3lgSQ3AR4KnAIcBTyhZ9sXOKy/P7zP05cfWVXXa4GQJEmStPYMGYXpeOBeSW7R5y8euO6tgUP606w3AD5eVZ9NcjLw0SSvBb4DvKfnfw/wwSSn01oe9lncrkiSJEmatQUDiCT/CLyxd0MiyS2Bv62ql8/3uao6Abj3lPQfATtPSb8c2HtguSVJkiStBUO6MD1iFDwAVNUvgT1nVyRJkiRJK9WQAGLD/pRo4Nr7GTadJ78kSZKkG6khw7h+CDgiyftow6o+g9UPfJMkSZK0HhlyE/Ubk5xAG0UpwD9U1RdnXjJJkiRJK86QFghow69eVVVfTnLTJJtX1SWzLJgkSZKklWfBeyCSPBs4FHhnT1oFfHqWhZIkSZK0Mg25ifp5wK7AxQBVdRpw21kWSpIkSdLKNCSAuKKqrhzNJNmIdjO1JEmSpPXMkADimCQvA26S5I+BTwCfmW2xJEmSJK1EQwKIA4ALgROB5wCfB+Z9CrUkSZKkG6chw7heA7yrTwAk2RX43xmWS5IkSdIKNGcAkWRD4Im0UZe+UFUnJXkU8DLgJsC9l6eIkiRJklaK+Vog3gNsC3wTeFuSM4FdgAOqymFcJUmSpPXQfAHETsAfVNU1STYDfgbcparOW56iSZIkSVpp5ruJ+sp+/wNVdTnwA4MHSZIkaf02XwvE3ZKc0N8HuHOfD1BV9QczL50kSZKkFWW+AOLuy1YKSZIkSeuEOQOIqjpzOQsiSZIkaeUb8iA5SZIkSQIMICRJkiQtwpwBRJIj+usblq84kiRJklay+W6i3jrJg4FHJ/kobfSla1XVcTMtmSRJkqQVZ74A4pXAAcA2wEETywrYfVaFkiRJkrQyzTcK06HAoUleUVX/sIxlkiRJkrRCzdcCAUBV/UOSRwMP6klHV9VnZ1ssSZIkSSvRgqMwJXk98Hzg5D49v6dJkiRJWs8s2AIBPBLYsaquAUhyCPAd4KWzLJgkSZKklWfocyC2HHu/xSwKIkmSJGnlG9IC8XrgO0mOog3l+iBsfZAkSZLWS0Nuov5IkqOB+9ECiJdU1XmzLpgkSZKklWdICwRVdS5w+IzLIkmSJGmFG3oPhCRJkiQZQEiSJEkabt4AIskGSU5arsJIkiRJWtnmDSD6sx++m+QOy1QeSZIkSSvYkJuotwa+l+SbwK9HiVX16JmVSpIkSdKKNCSAePXMSyFJkiRpnTDkORDHJLkjsENVfTnJTYENZ180SZIkSSvNgqMwJXk2cCjwzp60Cvj0LAslSZIkaWUaMozr84BdgYsBquo04LazLJQkSZKklWlIAHFFVV05mkmyEVCzK5IkSZKklWpIAHFMkpcBN0nyx8AngM/MtliSJEmSVqIhAcQBwIXAicBzgM8DL59loSRJkiStTENGYbomySHAN2hdl06tKrswSZIkSeuhBQOIJI8E/h34IRBg+yTPqar/mnXhJEmSJK0sQx4k9ybgIVV1OkCSOwOfAwwgJEmSpPXMkHsgLhgFD92PgAtmVB5JkiRJK9icLRBJHtfffi/J54GP0+6B2Bv41jKUTZIkSdIKM18Xpj8de38+8OD+/kLgljMrkSRJkqQVa84AoqqefkNWnGRb4APA7YFrgIOr6q1JbgV8DNgOOAN4YlX9MkmAtwJ7ApcB+1XVcTekDJIkSZLWrCGjMG0P/DXthP/a/FX16AU+ehXwt1V1XJLNgW8n+RKwH3BEVf1TkgNoz5l4CfAIYIc+/SHwjv4qSZIkaYUYMgrTp4H30J4+fc3QFVfVucC5/f0lSU4BVgF7Abv1bIcAR9MCiL2AD/RnTHw9yZZJtu7rkSRJkrQCDAkgLq+qt92QjSTZDrg37WF0txsFBVV1bpLb9myrgLPGPnZ2TzOAkCRJklaIIQHEW5O8Cvhv4IpR4tD7E5LcHPgk8IKqurjd6jA965S06z3xOsn+wP4Ad7jDHYYUQZIkSdIaMiSA+H3gqcDurO7CVH1+Xkk2pgUPH66q/+zJ54+6JiXZmtXPlDgb2Hbs49sA50yus6oOBg4G2Gmnna4XYEiSJEmanSEBxGOBO1XVlYtZcR9V6T3AKVV10Niiw4F9gX/qr4eNpf9Vko/Sbp6+yPsfJEmSpJVlSADxXWBLFv/06V1pLRcnJjm+p72MFjh8PMkzgZ/QHkwH8HnaEK6n04ZxvUHDyEqSJEla84YEELcDvp/kW1z3Hoh5h3Gtqq8y/b4GgD2m5C/geQPKI0mSJGktGRJAvGrmpZAkSZK0TlgwgKiqY5ajIJIkSZJWviFPor6E1cOpbgJsDPy6qm4xy4JJkiRJWnmGtEBsPj6f5DHAzjMrkSRJkqQVa4PFfqCqPs2AZ0BIkiRJuvEZ0oXpcWOzGwA7MeUJ0ZIkSZJu/IaMwvSnY++vAs4A9ppJaSRJkiStaEPugfCBbpIkSZKAeQKIJK+c53NVVf8wg/JIkiRJWsHma4H49ZS0mwHPBG4NGEBIkiRJ65k5A4iqetPofZLNgecDTwc+Crxprs9JkiRJuvGa9x6IJLcCXgg8GTgEuE9V/XI5CiZJkiRp5ZnvHoh/Bh4HHAz8flVdumylkiRJkrQizfcgub8Ffgd4OXBOkov7dEmSi5eneJIkSZJWkvnugVj0U6olSZIk3bgZJEiSJEkazABCkiRJ0mAGEJIkSZIGM4CQJEmSNJgBhCRJkqTBDCAkSZIkDWYAIUmSJGkwAwhJkiRJgxlASJIkSRrMAEKSJEnSYAYQkiRJkgYzgJAkSZI0mAGEJEmSpMEMICRJkiQNZgAhSZIkaTADCEmSJEmDGUBIkiRJGswAQpIkSdJgBhCSJEmSBjOAkCRJkjSYAYQkSZKkwQwgJEmSJA1mACFJkiRpMAMISZIkSYMZQEiSJEkazABCkiRJ0mAGEJIkSZIGM4CQJEmSNJgBhCRJkqTBDCAkSZIkDWYAIUmSJGkwAwhJkiRJgxlASJIkSRrMAEKSJEnSYDMLIJK8N8kFSU4aS7tVki8lOa2/3rKnJ8nbkpye5IQk95lVuSRJkiQt3SxbIN4PPHwi7QDgiKraATiizwM8AtihT/sD75hhuSRJkiQt0cwCiKr6CvCLieS9gEP6+0OAx4ylf6CarwNbJtl6VmWTJEmStDTLfQ/E7arqXID+etuevgo4ayzf2T1NkiRJ0gqyUm6izpS0mpox2T/JsUmOvfDCC2dcLEmSJEnjljuAOH/UNam/XtDTzwa2Hcu3DXDOtBVU1cFVtVNV7bTVVlvNtLCSJEmSrmu5A4jDgX37+32Bw8bSn9ZHY7o/cNGoq5MkSZKklWOjWa04yUeA3YDbJDkbeBXwT8DHkzwT+Amwd8/+eWBP4HTgMuDpsyqXJEmSpKWbWQBRVX82x6I9puQt4HmzKoskSZKkNWOl3EQtSZIkaR1gACFJkiRpMAMISZIkSYMZQEiSJEkazABCkiRJ0mAGEJIkSZIGM4CQJEmSNJgBhCRJkqTBDCAkSZIkDWYAIUmSJGkwAwhJkiRJgxlASJIkSRrMAEKSJEnSYAYQkiRJkgYzgJAkSZI0mAGEJEmSpMEMICRJkiQNZgAhSZIkaTADCEmSJEmDGUBIkiRJGswAQpIkSdJgBhCSJEmSBjOAkCRJkjSYAYQkSZKkwQwgJEmSJA1mACFJkiRpMAMISZIkSYMZQEiSJEkazABCkiRJ0mAGEJIkSZIGM4CQJEmSNJgBhCRJkqTBDCAkSZIkDWYAIUmSJGkwAwhJkiRJgxlASJIkSRrMAEKSJEnSYAYQkiRJkgYzgJAkSZI0mAGEJEmSpMEMICRJkiQNZgAhSZIkaTADCEmSJEmDGUBIkiRJGswAQpIkSdJgBhCSJEmSBjOAkCRJkjSYAYQkSZKkwQwgJEmSJA22ogKIJA9PcmqS05McsLbLI0mSJOm6VkwAkWRD4F+BRwD3AP4syT3WbqkkSZIkjdtobRdgzM7A6VX1I4AkHwX2Ak5eq6VaQXLIIcuyndp332XZjiRJktY9KymAWAWcNTZ/NvCHa6ks67XlClRujJYz+DKglNaMG+Mxz79bac3x/+31parWdhkASLI38LCqelaffyqwc1X99US+/YH9++xdgVOXtaDXdxvgZ2u5DOsb63z5WefLy/peftb58rPOl591vvzWtTq/Y1VttVCmldQCcTaw7dj8NsA5k5mq6mDg4OUq1EKSHFtVO63tcqxPrPPlZ50vL+t7+Vnny886X37W+fK7sdb5irmJGvgWsEOS7ZNsAuwDHL6WyyRJkiRpzIppgaiqq5L8FfBFYEPgvVX1vbVcLEmSJEljVkwAAVBVnwc+v7bLsUgrpjvVesQ6X37W+fKyvpefdb78rPPlZ50vvxtlna+Ym6glSZIkrXwr6R4ISZIkSSucAcQNkOThSU5NcnqSA9Z2edYlSd6b5IIkJ42l3SrJl5Kc1l9v2dOT5G29nk9Icp+xz+zb85+WZN+x9PsmObF/5m1Jsrx7uPIk2TbJUUlOSfK9JM/v6db7jCTZLMk3k3y31/mre/r2Sb7R6+9jfeAIkmza50/vy7cbW9dLe/qpSR42lu5xaEKSDZN8J8ln+7z1PUNJzuh/98cnObaneVyZoSRbJjk0yff7MX0X63x2kty1/75H08VJXrBe13lVOS1hot3o/UPgTsAmwHeBe6ztcq0rE/Ag4D7ASWNpbwQO6O8PAN7Q3+8J/BcQ4P7AN3r6rYAf9ddb9ve37Mu+CezSP/NfwCPW9j6v7QnYGrhPf7858APgHtb7TOs8wM37+42Bb/S6/DiwT0//d+Av+vu/BP69v98H+Fh/f49+jNkU2L4fezb0ODRnvb8Q+A/gs33e+p5tfZ8B3GYizePKbOv8EOBZ/f0mwJbW+bLV/YbAecAd1+c6twVi6XYGTq+qH1XVlcBHgb3WcpnWGVX1FeAXE8l70Q6K9NfHjKV/oJqvA1sm2Rp4GPClqvpFVf0S+BLw8L7sFlX1tWp/lR8YW9d6q6rOrarj+vtLgFNoT4C33mek192lfXbjPhWwO3BoT5+s89F3cSiwR78KtRfw0aq6oqp+DJxOOwZ5HJqQZBvgkcC7+3ywvtcGjyszkuQWtItw7wGoqiur6ldY58tlD+CHVXUm63GdG0As3SrgrLH5s3ualu52VXUutJNd4LY9fa66ni/97Cnp6npXjXvTrohb7zPUu9McD1xA+2fxQ+BXVXVVzzJeT9fWbV9+EXBrFv9drM/eArwYuKbP3xrre9YK+O8k306yf0/zuDI7dwIuBN7Xu+q9O8nNsM6Xyz7AR/r79bbODSCWblrfNIe0mo256nqx6QKS3Bz4JPCCqrp4vqxT0qz3Raqqq6tqR2Ab2hXsu0/L1l+t8xsgyaOAC6rq2+PJU7Ja32vWrlV1H+ARwPOSPGievNb5DbcRrQvwO6rq3sCvad1n5mKdryH9/qlHA59YKOuUtBtVnRtALN3ZwLZj89sA56ylstxYnN+b8eivF/T0uep6vvRtpqSv95JsTAsePlxV/9mTrfdl0LsYHE3rD7tlktFzeMbr6dq67cu3oHX1W+x3sb7aFXh0kjNo3Yt2p7VIWN8zVFXn9NcLgE/RAmWPK7NzNnB2VX2jzx9KCyis89l7BHBcVZ3f59fbOjeAWLpvATukje6xCa1J6/C1XKZ13eHAaESCfYHDxtKf1kc1uD9wUW8q/CLwJ0lu2Uc++BPgi33ZJUnu3/szP21sXeutXhfvAU6pqoPGFlnvM5JkqyRb9vc3AR5Ku/fkKOAJPdtknY++iycAR/b+sIcD+6SNGrQ9sAPthjuPQ2Oq6qVVtU1VbUeriyOr6slY3zOT5GZJNh+9px0PTsLjysxU1XnAWUnu2pP2AE7GOl8Of8bq7kuwPtf50Lutnabeib8nbSSbHwJ/v7bLsy5NtD/Ac4Hf0iLvZ9L6Hh8BnNZfb9XzBvjXXs8nAjuNrecZtBscTweePpa+E+2f2A+Bt9Mfmrg+T8ADaE2iJwDH92lP632mdf4HwHd6nZ8EvLKn34l2Qno6rSl8056+WZ8/vS+/09i6/r7X66mMjc7hcWjOut+N1aMwWd+zq+c70Uaj+i7wvVGdeFyZeb3vCBzbjy2fpo3oY53Pts5vCvwc2GIsbb2tc59ELUmSJGkwuzBJkiRJGswAQpIkSdJgBhCSJEmSBjOAkCRJkjSYAYQkSZKkwQwgJEmDJDk6ycMm0l6Q5N/m+cylsy+ZJGk5GUBIkob6CO3haeP24boPVpIk3cgZQEiShjoUeFSSTQGSbAf8DnB8kiOSHJfkxCR7TX4wyW5JPjs2//Yk+/X3901yTJJvJ/likq2XY2ckSUtjACFJGqSqfk57YvPDe9I+wMeA3wCPrar7AA8B3pQkQ9aZZGPg/wFPqKr7Au8FXremyy5JWnM2WtsFkCStU0bdmA7rr88AAvxjkgcB1wCrgNsB5w1Y312BewJf6jHHhsC5a77YkqQ1xQBCkrQYnwYOSnIf4CZVdVzvirQVcN+q+m2SM4DNJj53Fddt9R4tD/C9qtpltsWWJK0pdmGSJA1WVZcCR9O6Go1unt4CuKAHDw8B7jjlo2cC90iyaZItgD16+qnAVkl2gdalKcnvzXIfJEk3jC0QkqTF+gjwn6wekenDwGeSHAscD3x/8gNVdVaSjwMnAKcB3+npVyZ5AvC2HlhsBLwF+N7M90KStCSpqrVdBkmSJEnrCLswSZIkSRrMAEKSJEnSYAYQkiRJkgYzgJAkSZI0mAGEJEmSpMEMICRJkiQNZgAhSZIkaTADCEmSJEmD/f836wnI+CS50AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 792x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize skewed continuous features of original data\n",
    "distribution(raw_data, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For highly-skewed feature distributions such as `'delta ch(2)'`, it is common practice to apply a <a href=\"https://en.wikipedia.org/wiki/Data_transformation_(statistics)\">logarithmic transformation</a> on the data so that the very large and very small values do not negatively affect the performance of a learning algorithm. Using a logarithmic transformation significantly reduces the range of values caused by outliers. Care must be taken when applying this transformation however: The logarithm of `0` is undefined, so we must translate the values by a small amount above `0` to apply the the logarithm successfully.\n",
    "\n",
    "The code cell below will perform a transformation on the data and visualize the results. Again, note the range of values and how they are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAF2CAYAAAD+y36TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmYJWV59/Hvj0U2EVwQkcVxIbivI4ooosS4gOIuiRpwQxNNNJoo+rrgFmNcokZFiQu4BFRcQKMxiGJijArihiCCOsjIMqggg+xwv388dZgzZ053V/f0me6Z+X6u61ynq+qpqruWU1131VNPpaqQJEmSpD42WegAJEmSJK0/TCAkSZIk9WYCIUmSJKk3EwhJkiRJvZlASJIkSerNBEKSJElSbyYQmlaSQ5JUkjstglgOT/LwhY5jJkmeneTsJNckuXSh41lbSZZ0+8AhM5Qb7CuDzx+TLEvy+SRPTbLJSPle0x0ZZ99uP+h97BqKa8lQv2VJPtF3GnONay7LuNjMZn9O8/QkJyX5XZJrkyxPcmySh00wxkOSPHuK/qtt+w1Vt0/XFJ+XDJU7eZpy7xqZZpL8RZITk/y2254XJ/lakr9OstUMMS0Zmf7VSS7s9o+XJNl2jsu6ffd7u+9cxp9mukdNs242m895Dc3zJUmeOIlpS5M0kR+ENCGvA94MfH2hA5lKktsCRwKfBJ4FXLWwES2IpwDLgS2A3YD9gWOAQ5M8tqqu7MpdAOwF/GIW096Xth+8Cbih5zj/0c3nglnMZ7b2ZXxcc1nGRWM2+3OSTYFjgScARwP/Cvwe2JW2T5yU5OZV9YcJhHoI7f/ZR0b6r4ttv5h8FTh8TP9lI90/Bp4/ptyN66k7Yf4UcCDwceADwArg1sCjgHcC2wJv7RHXW4ATaNvo1sA+wBuAFyd5ZFX9vMc0hm1P+70tB06b5bgzuRh43GjPqrpunucz8BLgW8DnJjR9aSJMILRBSrJFVV29ALPeHdgUOLqqvrW2E0uyOXBdrV9vfPxhVZ0z1P3xJJ8BPgP8M/A3AN32+c6kghhadxfTTgrWuUkv4zowm/35lcCTgSdX1WdHhn0yyZ8B104gxikt5LZfIL+tqj7728oe5V5NSwafVFWfHxn22SRvAe7cM65fjszvc0neB/wf8Jkk915Ex7hreq7DRWsB//9pY1JVfvxM+aFd2SvgTjOUewbwI9oVyt/SrljtNFJma+AI4HfASuDzwIO66R8yw/RrzOfwbthRtCtRewHfBq4E3t0NO4h2x+Ji4HLgB8DBU0z/TcDfAr/q4vsmcLeRco/s5vGHbnpnAa8dimM0xqO6YZt3018GXNN9vwnYfGjaS7px/pp2on0+7Wr2zYe2w4OAT3fxXQS8shv3Ud2y/RE4BbjfmGV8Iu1k9grgUtoJ/W5jttH7u210Oe2q4YN7bqNp95Vue18FbD2yvIcMlbk/cGI3/yuAXwLv74YdPm4/mMW6WzI0n2XAJ4DnAed0cZ0GPGwk5pOBk8csy7KhbdsnrkNGxu/zexnEeBBwZrdtTwUePFJuynU2w/bao9sml9J+M98BHjU0/Kgxy3XUFNO6CXAJ8KVZHFvmZR1022g0zpNH9slx236m9Trjth/qtyfwNdpv5o/AScCec5kecBvaHZzzgatpdwW+BNx6hvW5DPhEj/V+MvCtGcpsQTvGHd93e04xncH+/9wphr+4G77fUL9pj9lD0xz9HNIN/zPgy916uwI4HXgZsGmPeI8Clvcody/asfES2m/nf4GHjPldHkf733Ql7X/FPwJbjWyzqf5nHAUsm2L7nTzUvW833hOBf+vW26VziHXWxxA/G/fHOxBaa0kOBT5Iu939SuC2tAPlA5Lct6ou74oeSavKcDjtH/Z+tKoRfexFu1p1VDcvaAfmge1o1SfeDryKdqAEuAPtIP5PtBPKfYAPJdmqqj4wMo9n0A7yL6adEL0NOD7JnavquiR3oB2Ij6Pdfr+GdoX2Dt34bwS+D7wHeCHthHRw9fNo4KndevlWtzyv7sb9i5E4/h8tCTiUdvV3uNrI0cDHWLUu/zHJ9sBjaNW7LqedQH8hyR2r6hqAJC+gJW8f7WLflrYdvpnknlW1spv+B4GnAa/vYngE8O/Mjy8DjweWAv89OjDJTWlVML5HO/FbSTtZeFBX5EPALsBzaEnN9WPmMd26G/VQ4H7dOFcDrwC+kuReVXXWLJarT1w3msXvBeAhtBP913TL8kbgS0mWVNWlPdbZVDHclrYfrgReRDtZfCHwH0kOqKqvMP3+PGoprVrJCdPNdxLrgJY0foK2vQfVci6bIYSZptlbknvSLjacwaqE5TDab+uBVfWj2UyPlkjdDvgH4DxgR9qxcut+4axZV7/GVL+Zok7/9VVVtO15M1riMklfBt4F7E1LumDmY/YFtJPlz7GqahSsqiZ4h25a/0rbtktpx7odaNtlRmPWzQ1VdUM37L7A/9ASm+fRTrhfAHwtyYOq6vvdOLsBP6T9z1oJ3A14bRffQV2ZJ3Tr4Eesqno21ztm/wp8BXgmsGXfWOd6DJEWPIPxs7g/zHxVeVPalfBvjPQfXLX+2657D9o/g5ePlHsPPa5ud2ULeNOY/kd1ww6cYfxNaNX2/g340Zhpn83qdwSe3PV/0Ej3zaaZx592ZfYd6nd3hu6YDPV/ddf/nl33kq77NCBTbIfXDvXbjFYn+Vrg9kP9H9eVfWjXfVPaCeJHRqa5hJYEvWRoG10PHDZS7og+26jHvvLIbvjTRpb3kK576fD6mGIah3dlNhuzLDOtuyVD/ZZ1y77bUL9taXX2Pz7U72T6XTWeKa7BMvb6vQzN4xLg5kP9BuvoL/qusynW49uB64a3VRfbWcBp0+3PU0zvaV25R/aY97yug6HttMZV9Wm2fd9p9tn2x9Hu4mw/1O9m3b70uTlM7/LhdTCLbbqM8VfmC1g6EsdU5Z483fYEQjvuDD7TXtVn5jsQW3TDj5hi+Nhj9kzTHRPv/+u2+SYzlD9qivXypqEyJ9HuXN1kZJ8+E/jCDHE8g/Z/8JYj222NO0fM/g7E58eUnTFW5ngM8ePHVpi0tvagPRS32p2EavWlz6Vd5QV4AO0g+pmR8Y8b7uha/dhs6LNpzziuY8zVsiS7JzkmyW9oJ9rXAs/t4h51YlUN19H+Sfe9W/f9w278Y5M8Ocmte8a2T/c92urPoPuhI/2/UFU1xbS+Mvij2lXFc4CfV9Wvhsr8rPvetfvei3ZC88nhdUu7g/OzofgeQPuH/emReR47RSyzlUHoUww/m3Yi9sEkz0iy6xTlpjPduhv1nar69aCj2l2YwUO3k9L39zLwf1V1yVD36D4513W2D235b3xWpaqupz3sfu8kN+s5nbmY73UwF/M5zX1oVbduvHNRVZfRroyPLksfpwD/kOTFSe6RJDOOscpXaNVRRj9njJT70RTlBncBpprn01h1HL2WdudlbaxxTJjlMXvNCSY7JflgknNpFwmupVUX3Z62381kBWuul/d3096Ktk0/A9wwdCwNrQrb4FhKkpsleWuSX9DucF5Lu7sU2p3r+bbacyqziHU+jrvaCJlAaG3dovse18rJhUPDd+q+V4yUuWik+2BW/wfVt/WaFd0J0I26W7Mn0uqAHkartnB/WkstW4yZxu9HugcPoW0J0J1sPZL2u/k4cGGS7yaZ6SRhqnV04chwpig37JKR7mum6Hdj3Kz6p/k1Vl+31wL3AG7ZDR9so9FtMto9V4N/TGOXr1rrPA+j1f1+P/DrJKcnedIs5jGb1nbGLddFwM6zmMZs9f29DKy2T9aqByMH++Rc19ktpokhtGdHZuO87vt2PcrO6zqYo/mc5nTrcrbrEdpJ+gnAy2mtJf0myWvTr+ni31fVqWM+V4yUu3yKcoNjyWB7jiZUX2XVSfV8tH602jFhDsfs1XTr6ATgAFrS8PBu/Dd3Rfps32vHrJfzu2G3oF3Bfw1rHktfBNx8aDt9lFZd6D20qqD3p1UF7BvHbI3ug71inafjrjZCPgOhtTX4R3ybMcNuQ3vWAVYd3G5Ne0h5YMeRcb5IO9AO9G1JYtxV571oJzQPqaEWZNamPe+q+gbwjSRb0OrtvoFWb3xJVf12itGG19FwQjRYZ78bnc1c45vCYPqHAD8dM3zw/MNgG+1Ie4iOoe75sD+tTvL3pypQVT8EntRto6W0+vGf7p5LOL3HPGaz7sYt147Ab4a6r6LdvRk1epLbV9/fS29zXGe/nyaGYs1keian0q5iPpb2fM505n0dTEjfbT/duhxej72mV1UraCeaL0yyB+2iyutpdeOP6BX52juV9hzJAbTqQ4PYLumGkWQla38OsX/3PTg+r+0x+46038Azq+rGO75JHruWcQ5cSquC9D7as2hrqKobkmxJa/728Kp691Ac95jFvK6iPYs36pas+T8D1jz29Yq1+17b4642Qt6B0No6i3bV9qDhnkkeRPtHMLjF/V3aAe4pI+Ov1l1Vvxu58vOTocHXANO+uGjE4KHDG6slJbk57cC+Vqrq6qr6Ou2B5W2A209TfLAODhrp//Tue40HiufZt2lJwp2muOo4eGD4u7R/OE8dGX807lnrXpT0OOADY66GrqGqrqvWlOJraMepu3SDBgnlbPaDqTxw+HZ92kut9qc9rD9wLvAnSW4yVG4f2vMSw/rG1ff3MmvTrLNxvklb/iVDMWxKu/r9g1r1UH3feV8DvAM4YKorl0kekWRrJrMOrmZ+9olhfbf9N4H9M/RStO7vx7L6svSd3o2q6qyqehXtLuPd12JZZqW7I/Nu4LFJHj+JeSTZnfZswg9o9fqh/zF7qt/buPE3Z9Wxdq1U1R9pDyXfi/as0BrH067oFrSr/6PNFh8yZrJT7bvnAjsmudWgR5I70rMq1yxiHR5nNscQbeS8A6G+HpXkwpF+f6iqE5O8llZ/8hO0ev07024Zn027jUtVnZXk34E3drd4v0+7vTy4MtTnpWBn0P5R/yftH+r5Q7eWx/k27Sra+5K8jnai/2pak5Hb9ZjfatJaMtqH1mrGecCtaFdqzqc1FThWVf00yTHA4d0Vnm/TrrS9Bjimqn4821hmo6ouS/IPtPWwA62e9B9o2+mhtAfy/n1oG72h20aDVpgeM8tZ3rv7p3cTWhWIA2iJ4om09TVWkgNorSd9gXaXahtas7orWXVSP6jL/bIkX6G1GjPXK9YXAf+V5HBWtcK0Da1FnoFju5g+kuQoWqL4Utr6G9Yrrqq6vs/vpa+e62ycf6GdzJzY/TYuo7Vm9Cesuio8W2+hnax8qltXX6Rdgd8FeBKt5ZybV9UV87kOOmcAf53kabS7fCtrdi1pjdN327+Rto+flOSttAslr6CdzL5hNtNLsh2tquEnac8nXUs7eb458F89Yr5VkgeO6X9hVS0b6t52inKXDK23NwD3BI5L8jHaM2YraMfOPWnbuu/7Eu7QzW9TWmtID6W1WvZb4KlDzy31PWZfRLsKf1CSH9Oazv0V7eHgc4E3J7metv7+rmeMfb2UdtHnq0k+TLtzeyvgvrSHyg+rqj8k+Q7teHBBF/+zGV898gzgId1v+ULauzyW0Z5deCPt2bV3sur/zVR3uucU61ocQ7Sx6/u0tZ+N88OqVkzGfU4fKjdo0/1q2oF9uvdA/J5V7xjYnx4tKHXj701LPK5iqFUjpmm7m5ak/IDWrOsvaAfGw9uuv1q51Vra6PotYfUWdPYCjqclD4P22T8D7DE0zthWa1j1Hohzaf/UzmXq90Cs0bIIU7RwxJjWZ6aaDi0R+AbtH/SVtAewPwLcdYZttPfwepjFvnJlt5yfpyUQo60jja7fPWjNev6q28YX05K1BwyNsyntlvwKWtJZs1h3S4b6LaOduD632y+u7vaTh48Z//m0E9sraSc492PNlnNmiuuQkWn2+b0sY3zrLMP7/ozrbJrttQftpOEP3birvQdiuv15mmmmW7Zv0JL8a2kP6x/Dmm3Pz8s66Lpv0y33ym7YyTNt+5mm2Xfbd+UewAzvgegzPdqV6w/SqhpeTvutnsJQ61DTrPtlTH2sfu/IMWOqcl8ameYm3XY6qdtG13b72NeAvwK2nCGmJSPTv4Z28v912huYtx0zTt9j9uNpJ9/Xsvpx5N60KlFXdPveG2i/89X2gyniPYp+74G4Cy0hXEHbf5fTjpWPGVn2r9D2yRXAe1n1/27foXJ3pt0puKIbdtTIMp7erYsf0d5xcTLjW2H607nEylocQ/xs3J9UDRJ/ad3rroy/lXZg//VM5SVJkrSwrMKkdaa7VXp3WnOoN9Ba2Ph74NMmD5IkSesHEwitSytpt2QPo9Wz/A2tibvXLWRQkiRJ6s8qTJIkSZJ6sxlXSZIkSb2ZQEiSJEnqzQRCkiRJUm8mEJIkSZJ6M4GQJEmS1JsJhCRJkqTeTCAkrfeSnJ7k8FmU3zdJJbnVBMMaN98l3XyX9ih7eJKPzHL630vyxLlHqIFu/Z8+oWkvS/L3Q92V5MkTmtfElkPSxssEQtKiluSo2SQHc5zHIUkun+Q8ZiPJrYGXAm8a6vfKJKckuSzJxUm+mOTuI6O+EXhrkk2GxjskyckzzK/GfH44j4u0xknzQujWxWD5rk9yaZJTk7y5W+fD3g48tOd0Z5uQ3h94/2xi7xHDVMlp7+WQpL5MICRp8Xku8L2q+uVQv31pJ50PAh4OXAd8Lckthsp8GdgWePQc5vk8YKehz35zmMbEJdkkyaZrMYkraMu3C/AA4F3A44DTk9xlUKiqLq+q361VsCOS3KSb9sVVdcV8Tnsqk1gOSTKBkLReSXLrJMcnuTLJuUmePabMdkmOTLIiycok35yq2lCSfYGPAtsMXZ0+vBv2jO6q/8puWp9JsvMM8SXJy5KcneTqJMuTvGWk2O2SnJjkiiRnJHnEyPC/AE4Y7lFVj6yqj1bV6VX1E+CZwA7A3kNlrqclEX8+XYxTuLSqLhz63HjSmWTnJMcmuaT7/EeS3YeG37HbJhcm+WOS05IcMDT8ZOB2wNsG67jrv8adn9Gr+YMySR7TVcW5BrhLN+xZ3fq7KsnPk/zd8N2XKVS3fBdU1VlV9QlgL+BS4ANDcaxW9SfJPZKc1N0BWpnkR0kelmQJ8I2u2MVd7EcNljvJEUnenuRi4H+7/uPuxtymW69XdPv1M4bmPfbuQlav+vSr7vuUrv/JUyzHJklek+S8bv/8SZIDx8zrSTPso5I2YiYQktY3RwF3Av4UeDzwl8CSwcAkAf4D2Bk4ALgP8N/A15PsNGZ63wZewqor0zvRqn0A3AR4HXCvblq3Ao6ZIb5/BF4DvAW4G/AU4LyRMm8G3tNN9xTg2CQ37eK/BXBX4NQZ5rMt7Rh+yUj/7zGPVVaSbE07Qb6qm+5ewAW0ux9bd8VuCnwFeARtmT4LfC7JnbvhTwSWA29g1TqejS2BVwPPp62bc5M8j7auX0tLKF4GvAL469kuY1VdTkse9kmywxTF/p223HvS9qnDaevkPOBJXZm70ZbtxUPjPQMI8BDavjqV19OSxnsDRwIfmyrpncKe3fejuhimehbmxcA/0NbVPYDP07bVvUfKTbmPShJV5cePHz/rxQf4E6CAvYf63Q64Hji86344cDmw1ci4PwRe3v29bzedW3XdhwCX95j/nbvxdpli+E1pJ5UvmGL4km785w/127nr9+Cu+95d9+1niOXTwA+ATUf6Pw64AdhsFuu1gCu79Tb4PL0b9mzgbCBD5TcFfgc8dZppfgd49VD3MuDvR8qssd6n2DYF3G+k3K+BZ470ewlwxjQxTbmdaSfeBezZdR8OnD40/DLg4CnGXS3mof4nAz8eU361ddGN+28jZb4GfGJkv1k6Zrs9eYYyo8vxG+C1Y+IcndeU+6gfP378bIYkrT/uQjs5/t6gR1Wdm+T8oTL3A7amVScZHndL4I6zmVmS+9LuQNwbuAXtSjLAbrQr6qPuCmwBnDTDpH889Pcg9sFDvFt131dNE9c7gQfTTuiuHxl8ZRfnlrREoK9/AP5zqPui7vt+wO2BlSPrc2u69ZlkG9p6OoB29Xvzbv7Dy7k2rqMlgHTz2wHYFfhgkiOGym3Gqm00W4Pxaorh7wQ+lORg2vb9bFX9rMd0v99z/v83pnv/nuP2kuRmwG3pqlIN+RbwmJF+0+2jkjZyJhCS1id9Tg43oZ38PmTMsMt6z6idFH+VdiX4mcAKWhWm/6FVbZprfADXDv6oqupOzAdVSn/bfd+cVmVmNK5/AQ4CHlarP2Q9cAvgqmrVcmbjwqo6Z0z/TWgn7weNGfb77vvttCv4f0+7W3EF8DGmXk8DN7DmOtt8TLmrRxKlwbp6Aa0K2ny4Ky15WDZuYFUdnuSTtAfUHwm8LskLqmqmpnb/OA+x3dB937iukoxbT32NS5JG+023j0rayJlASFqfnEk7ibk/3Yljkt1oV1UHTgN2BG6Y4gR7nGto1XKG3ZmWMLyqqn7VzWumdyycAVxNa8Ho7J7zHvULWqJz1256N0rybtqJ/L7TXP2+O20dzJfTaA9l/7aqLp2izIOBj1XVZ7s4B3d7fj5UZtw6vhjYOsnNqmqQ3I3WxV9DVV2U5DfAHavqY/0XZbyubv8LgG9W1cXTzPds2nZ9T3fn47nAR2jLBmsu32w8sJvWcPeZ3d+DmIafHRldTzPGUFWXdXfrHgx8fWjQgxnZ1yRpOl5NkLTeqKqzaNVsPphkr+7Bz6No1XYGvkaronF8kkcnuX1X9vVJxt2VgHbVecskj0hyq+7h4F/TkoEXJblDkv1p71mYLr6VwLuBt3QtBN0xyZ5J/moWy3hDtwwPHu6f5H3As2gn85ckuU33GX2w9SGsXhVpbX2Sdkfn+CQP7dbnPknekVUtMf0ceEKS+ya5B/AJWhWmYcuAh6S16DR4X8J3aVfo35LkTkmeRP+HoA8HXt61vLRHkrsn+cskr5xhvAytuz261o7+D9huqnkn2SrJ+9JaiFqS5AGsftJ9Lu0K/v5Jdpjjw8ZPTPK8JLt3y7AfrYlZqupK2jMlr0hytyQPYtWD/gMraL+DRybZMcl2U8znbcDfJ/nzJH+S5A20feYdc4hZ0kbKBELS+uYQWpOVXwe+SGsdZ9lgYFUVrT7314F/A86iPXC8B6vqcq+mqr5Na4XnGNrV3pd3V6IPprX0dAatjv9Le8T3SuCttJaYzqS1SLTLrJawtcLztKz+voO/prW8dBKtatPgM/xG451p74n46CznN6Vq7yvYB/gl8BngZ8DRtCpWgxagXko7gf0fWmtM3+n+HvZa2nMLv6C7ol5VvweeTmu96SfAobT11ieuD9Ee8H4m8KNufoeyqjnTqWxNW2/n056leSltP7p7VZ05xTjX05b3aNr+9Hla0vHSLpbf0PaPN9OSrff2WYYRh9Nac/ox8FfAs6rqlKHhg+aKTwE+SGuV6kZVdR3wt7S7IucDx08xn/fQkoh/Bk4HngA8qarm9cWBkjZsaf9rJUmLSZL/A95fVR+fxThvA7arqkMnF5kkaWPnHQhJWpyez+yP0SvoeQVfkqS5mugdiCTLgJW027/XVdXS7iVJn6K1Nb2M1o74Jd3Ln95Nq3pwBXBIVc3ng4CSJEmS1tK6uAPxsKq6d1UN3qh5GHBSVe1Oq8t7WNf/0cDu3edQ4Ig1piRJkiRpQS1EFaYDaQ+i0X0/fqj/x6r5DrB9kp3GTUCSJEnSwpj0eyAK+K8kBXywqo4EdqyqCwCq6oIkgzdb7gycNzTu8q7fai9SSnIo7Q4F22yzzf3ufOc7T3gRJEmSpA3f97///d9W1Q4zlZt0ArF3VZ3fJQknJpnqxUcw/g2uazyg0SUhRwIsXbq0Tj311PmJVJIkSdqIJTm3T7mJVmGqqvO77xW0drP3BC4aVE3qvld0xZfT2ggf2IUp2myXJEmStDAmlkAk2SbJtoO/gT+jvbTmBNrLmei+By+7OQH4yzQPBP4wqOokSZIkaXGYZBWmHYHPt9ZZ2Qz496r6zySnAJ9O8hzg18BTuvJfpjXheg6tGddnTTA2SZIkSXMwsQSiqn4J3GtM/98B+43pX8ALJxWPJEmSpLXnm6glSZIk9WYCIUmSJKk3EwhJkiRJvZlASJIkSerNBEKSJElSbyYQkiRJknozgZAkSZLUmwmEJEmSpN5MICRJkiT1ZgIhSZIkqTcTCEmSJEm9mUBIkiRJ6s0EQpIkSVJvJhCSJEmSejOBkCRJktSbCYQkSZKk3kwgJEmSJPVmAiFJkiSpNxMISZIkSb2ZQEiSJEnqzQRCkiRJUm8mEJIkSZJ6M4GQJEmS1JsJhCRJkqTeTCAkSZIk9WYCIUmSJKk3EwhJkiRJvZlASJIkSerNBEKSJElSbyYQkiRJknozgZAkSZLUmwmEJEmSpN5MICRJkiT1ZgIhSZIkqTcTCEmSJEm9mUBIkiRJ6s0EQpIkSVJvJhCSJEmSejOBkCRJktSbCYQkSZKk3kwgJEmSJPVmAiFJkiSpNxMISZIkSb2ZQEiSJEnqzQRCkiRJUm8mEJIkSZJ6M4GQJEmS1JsJhCRJkqTeTCAkSZIk9TbxBCLJpkl+kORLXfftk3w3ydlJPpXkJl3/Lbruc7rhSyYdmyRJkqTZWRd3IF4MnDnU/VbgX6pqd+AS4Dld/+cAl1TVnYB/6cpJkiRJWkQmmkAk2QXYH/hQ1x3g4cBxXZGjgcd3fx/YddMN368rL0mSJGmRmPQdiHcBLwdu6LpvCVxaVdd13cuBnbu/dwbOA+iG/6Erv5okhyY5NcmpF1988SRjlyRJkjRiYglEkgOAFVX1/eHeY4pWj2GrelQdWVVLq2rpDjvsMA+RSpIkSeprswlOe2/gcUkeA2wJ3Ix2R2L7JJt1dxl2Ac7vyi8HdgWWJ9kM2A74/QTjkyRJkjRLE7sDUVWvrKpdqmoJcBDw9ap6OvAN4MldsYOB47u/T+i66YZ/varWuAMhSZIkaeEsxHsgXgG8NMk5tGccPtz1/zBwy67/S4HDFiA2SZIkSdOYZBWmG1XVycDJ3d+/BPYcU+Yq4CnrIh5JkiRJc+ObqCVJkiT1ZgIhSZIkqTcTCEmSJEm9mUBIkiRJ6s3+mRj8AAAVY0lEQVQEQpIkSVJvJhCSJEmSejOBkCRJktSbCYQkSZKk3kwgJEmSJPVmAiFJkiSpNxMISZIkSb2ZQEiSJEnqzQRCkiRJUm8mEJIkSZJ6M4GQJEmS1JsJhCRJkqTeTCAkSZIk9WYCIUmSJKk3EwhJkiRJvZlASJIkSerNBEKSJElSbyYQkiRJknozgZAkSZLUmwmEJEmSpN5MICRJkiT1ZgIhSZIkqTcTCEmSJEm9mUBIkiRJ6s0EQpIkSVJvJhCSJEmSejOBkCRJktSbCYQkSZKk3kwgJEmSJPVmAiFJkiSpNxMISZIkSb3NmEAk2TvJNt3fz0jyziS3m3xokiRJkhabPncgjgCuSHIv4OXAucDHJhqVJEmSpEWpTwJxXVUVcCDw7qp6N7DtZMOSJEmStBht1qPMyiSvBJ4B7JNkU2DzyYYlSZIkaTHqcwfiacDVwHOq6kJgZ+BtE41KkiRJ0qI04x2ILml451D3r/EZCEmSJGmjNGUCkWQlUFMNr6qbTSQiSZIkSYvWlAlEVW0LkOQNwIXAx4EAT8eHqCVJkqSNUp9nIB5ZVe+vqpVVdVlVHQE8adKBSZIkSVp8+iQQ1yd5epJNk2yS5OnA9ZMOTJIkSdLi0yeB+AvgqcBF3ecpXT9JkiRJG5lpW2Hq3vnwhKo6cB3FI0mSJGkRm/YORFVdT3sDtSRJkiT1ehP1/yZ5L/Ap4I+DnlV12sSikiRJkrQo9UkgHtR9v2GoXwEPn26kJFsC/w1s0c3nuKp6XZLbA8cCtwBOA55ZVdck2YL2grr7Ab8DnlZVy2axLJIkSZImrM+bqB82x2lfDTy8qi5PsjnwrSRfAV4K/EtVHZvkA8BzgCO670uq6k5JDgLeCjxtjvOWJEmSNAEztsKUZLsk70xyavd5R5LtZhqvmsu7zs27z+DOxXFd/6OBx3d/H9h10w3fL0lmsSySJEmSJqxPM64fAVbSmnJ9KnAZ8NE+E+/eHfFDYAVwIvAL4NKquq4rshzYuft7Z+A8gG74H4Bb9lsMSZIkSetCn2cg7lhVw2+efn2XFMyoa8Xp3km2Bz4P3GVcse573N2GGu2R5FDgUIDddtutTxiSJEmS5kmfOxBXJnnwoCPJ3sCVs5lJVV0KnAw8ENg+ySBx2QU4v/t7ObBrN4/NgO2A34+Z1pFVtbSqlu6www6zCUOSJEnSWuqTQPwV8L4ky5IsA94LvGCmkZLs0N15IMlWwJ8CZwLfAJ7cFTsYOL77+4Sum27416tqjTsQkiRJkhZOn1aYfgjcK8nNuu7Lek57J+Do7m3WmwCfrqovJTkDODbJm4AfAB/uyn8Y+HiSc2h3Hg6a3aJIkiRJmrQZE4gk/wj8c1cNiSQ3B15WVa+ebryq+jFwnzH9fwnsOab/VcBTesYtSZIkaQH0qcL06EHyAFBVlwCPmVxIkiRJkharPgnEpt1booEbn2fYYprykiRJkjZQfZpx/QRwUpKP0ppVfTarXvgmSZIkaSPS5yHqf07yY1orSgHeWFVfnXhkkiRJkhadPncgoDW/el1VfS3J1km2raqVkwxMkiRJ0uIz4zMQSZ4HHAd8sOu1M/CFSQYlSZIkaXHq8xD1C4G9gcsAqups4NaTDEqSJEnS4tQngbi6qq4ZdCTZjPYwtSRJkqSNTJ8E4ptJXgVsleQRwGeAL042LEmSJEmLUZ8E4jDgYuAnwPOBLwPTvoVakiRJ0oapTzOuNwD/1n0ASLI38L8TjEuSJEnSIjRlApFkU+CptFaX/rOqTk9yAPAqYCvgPusmREmSJEmLxXR3ID4M7Ap8D3hPknOBvYDDqspmXCVJkqSN0HQJxFLgnlV1Q5Itgd8Cd6qqC9dNaJIkSZIWm+keor6me/6BqroK+LnJgyRJkrRxm+4OxJ2T/Lj7O8Adu+4AVVX3nHh0kiRJkhaV6RKIu6yzKCRJkiStF6ZMIKrq3HUZiCRJkqTFr8+L5CRJkiQJMIGQJEmSNAtTJhBJTuq+37ruwpEkSZK0mE33EPVOSR4KPC7JsbTWl25UVadNNDJJkiRJi850CcRrgcOAXYB3jgwr4OGTCkqSJEnS4jRdK0zHAccleU1VvXEdxiRJkiRpkZruDgQAVfXGJI8D9ul6nVxVX5psWJIkSZIWoxlbYUryFuDFwBnd58VdP0mSJEkbmRnvQAD7A/euqhsAkhwN/AB45SQDkyRJkrT49H0PxPZDf283iUAkSZIkLX597kC8BfhBkm/QmnLdB+8+SJIkSRulPg9RH5PkZOD+tATiFVV14aQDkyRJkrT49LkDQVVdAJww4VgkSZIkLXJ9n4GQJEmSJBMISZIkSf1Nm0Ak2STJ6esqGEmSJEmL27QJRPfuhx8l2W0dxSNJkiRpEevzEPVOwE+TfA/446BnVT1uYlFJkiRJWpT6JBCvn3gUkiRJktYLfd4D8c0ktwN2r6qvJdka2HTyoUmSJElabGZshSnJ84DjgA92vXYGvjDJoCRJkiQtTn2acX0hsDdwGUBVnQ3cepJBSZIkSVqc+iQQV1fVNYOOJJsBNbmQJEmSJC1WfRKIbyZ5FbBVkkcAnwG+ONmwJEmSJC1GfRKIw4CLgZ8Azwe+DLx6kkFJkiRJWpz6tMJ0Q5Kjge/Sqi6dVVVWYZIkSZI2QjMmEEn2Bz4A/AIIcPskz6+qr0w6OEmSJEmLS58Xyb0DeFhVnQOQ5I7AfwAmEJIkSdJGps8zECsGyUPnl8CKCcUjSZIkaRGb8g5Ekid2f/40yZeBT9OegXgKcMo6iE2SJEnSIjNdFabHDv19EfDQ7u+LgZtPLCJJkiRJi9aUCURVPWttJpxkV+BjwG2AG4Ajq+rdSW4BfApYAiwDnlpVlyQJ8G7gMcAVwCFVddraxCBJkiRpfvVphen2wN/QTvhvLF9Vj5th1OuAl1XVaUm2Bb6f5ETgEOCkqvqnJIfR3jPxCuDRwO7d5wHAEd23JEmSpEWiTytMXwA+THv79A19J1xVFwAXdH+vTHImsDNwILBvV+xo4GRaAnEg8LHuHRPfSbJ9kp266UiSJElaBPokEFdV1XvWZiZJlgD3ob2MbsdBUlBVFyS5dVdsZ+C8odGWd/1MICRJkqRFok8C8e4krwP+C7h60LPv8wlJbgp8FnhJVV3WHnUYX3RMvzXeeJ3kUOBQgN12261PCJIkSZLmSZ8E4h7AM4GHs6oKU3Xd00qyOS15+GRVfa7rfdGgalKSnVj1TonlwK5Do+8CnD86zao6EjgSYOnSpWskGJIkSZImp08C8QTgDlV1zWwm3LWq9GHgzKp659CgE4CDgX/qvo8f6v+iJMfSHp7+g88/SJIkSYtLnwTiR8D2zP7t03vT7lz8JMkPu36voiUOn07yHODXtBfTAXyZ1oTrObRmXNeqGVlJkiRJ869PArEj8LMkp7D6MxDTNuNaVd9i/HMNAPuNKV/AC3vEI0mSJGmB9EkgXjfxKCRJkiStF2ZMIKrqm+siEEmSJEmLX583Ua9kVXOqNwE2B/5YVTebZGCSJEmSFp8+dyC2He5O8nhgz4lFJEmSJGnR2mS2I1TVF+jxDghJkiRJG54+VZieONS5CbCUMW+IliRJkrTh69MK02OH/r4OWAYcOJFoJEmSJC1qfZ6B8IVukiRJkoBpEogkr51mvKqqN04gHkmSJEmL2HR3IP44pt82wHOAWwImEJIkSdJGZsoEoqreMfg7ybbAi4FnAccC75hqPEmSJEkbrmmfgUhyC+ClwNOBo4H7VtUl6yIwSZIkSYvPdM9AvA14InAkcI+qunydRSVJkiRpUZruRXIvA24LvBo4P8ll3WdlksvWTXiSJEmSFpPpnoGY9VuqJUmSJG3YTBIkSZIk9WYCIUmSJKk3EwhJkiRJvZlASJIkSerNBEKSJElSbyYQkiRJknozgZAkSZLUmwmEJEmSpN5MICRJkiT1ZgIhSZIkqTcTCEmSJEm9mUBIkiRJ6s0EQpIkSVJvJhCSJEmSejOBkCRJktSbCYQkSZKk3kwgJEmSJPVmAiFJkiSpNxMISZIkSb2ZQEiSJEnqzQRCkiRJUm8mEJIkSZJ6M4GQJEmS1JsJhCRJkqTeTCAkSZIk9WYCIUmSJKk3EwhJkiRJvZlASJIkSerNBEKSJElSbyYQkiRJknozgZAkSZLU22YLHYAkDeToo9fJfOrgg9fJfCRJ2hB5B0KSJElSbyYQkiRJknqbWAKR5CNJViQ5fajfLZKcmOTs7vvmXf8keU+Sc5L8OMl9JxWXJEmSpLmb5B2Io4BHjfQ7DDipqnYHTuq6AR4N7N59DgWOmGBckiRJkuZoYglEVf038PuR3gcCg6ckjwYeP9T/Y9V8B9g+yU6Tik2SJEnS3KzrVph2rKoLAKrqgiS37vrvDJw3VG551++CdRyfpBHrqmUkSZK0flgsD1FnTL8aWzA5NMmpSU69+OKLJxyWJEmSpGHrOoG4aFA1qfte0fVfDuw6VG4X4PxxE6iqI6tqaVUt3WGHHSYarCRJkqTVresE4gRg8Aang4Hjh/r/Zdca0wOBPwyqOkmSJElaPCb2DESSY4B9gVslWQ68Dvgn4NNJngP8GnhKV/zLwGOAc4ArgGdNKi5JkiRJczexBKKq/nyKQfuNKVvACycViyRJkqT5sVgeopYkSZK0HjCBkCRJktSbCYQkSZKk3kwgJEmSJPVmAiFJkiSpNxMISZIkSb2ZQEiSJEnqzQRCkiRJUm8mEJIkSZJ6m9ibqCVpscrRR6+T+dTBB6+T+UiStC55B0KSJElSbyYQkiRJknozgZAkSZLUmwmEJEmSpN5MICRJkiT1ZgIhSZIkqTcTCEmSJEm9mUBIkiRJ6s0EQpIkSVJvJhCSJEmSejOBkCRJktSbCYQkSZKk3kwgJEmSJPVmAiFJkiSpNxMISZIkSb2ZQEiSJEnqzQRCkiRJUm8mEJIkSZJ622yhA5CkDVWOPnqdzasOPnidzUuStHHzDoQkSZKk3kwgJEmSJPVmAiFJkiSpN5+BkCT15nMdkiTvQEiSJEnqzTsQkrQBWJd3BiRJGzfvQEiSJEnqzQRCkiRJUm8mEJIkSZJ6M4GQJEmS1JsJhCRJkqTeTCAkSZIk9WYCIUmSJKk33wMhSdIGxjeGS5okEwhJ0qK0rk6CPQGWpNkxgZDWU755WJof/pYkaXZ8BkKSJElSbyYQkiRJknozgZAkSZLUmwmEJEmSpN4WVQKR5FFJzkpyTpLDFjoeSZIkSatbNK0wJdkUeB/wCGA5cEqSE6rqjIWNbHq2tT13rjtJkqT1z6JJIIA9gXOq6pcASY4FDgQWdQIhSZI2HF7ckma2mBKInYHzhrqXAw9YoFgWJdsqnztfSCVJk+H/prnbENfduvo/6LpbWKmqhY4BgCRPAR5ZVc/tup8J7FlVfzNS7lDg0K5zD+CseQ7lVsBv53maWlzcxhs2t++Gz228YXP7btjcvovb7apqh5kKLaY7EMuBXYe6dwHOHy1UVUcCR04qiCSnVtXSSU1fC89tvGFz+2743MYbNrfvhs3tu2FYTK0wnQLsnuT2SW4CHAScsMAxSZIkSRqyaO5AVNV1SV4EfBXYFPhIVf10gcOSJEmSNGTRJBAAVfVl4MsLHMbEqkdp0XAbb9jcvhs+t/GGze27YXP7bgAWzUPUkiRJkha/xfQMhCRJkqRFzgRiSJJHJTkryTlJDlvoeDR/kuya5BtJzkzy0yQvXuiYNBlJNk3ygyRfWuhYNL+SbJ/kuCQ/637Ley10TJpfSf6uO0afnuSYJFsudEyauyQfSbIiyelD/W6R5MQkZ3ffN1/IGDU3JhCdJJsC7wMeDdwV+PMkd13YqDSPrgNeVlV3AR4IvNDtu8F6MXDmQgehiXg38J9VdWfgXridNyhJdgb+FlhaVXenNahy0MJGpbV0FPCokX6HASdV1e7ASV231jMmEKvsCZxTVb+sqmuAY4EDFzgmzZOquqCqTuv+Xkk78dh5YaPSfEuyC7A/8KGFjkXzK8nNgH2ADwNU1TVVdenCRqUJ2AzYKslmwNaMeR+U1h9V9d/A70d6HwgMXiN9NPD4dRqU5oUJxCo7A+cNdS/HE8wNUpIlwH2A7y5sJJqAdwEvB25Y6EA07+4AXAx8tKui9qEk2yx0UJo/VfUb4O3Ar4ELgD9U1X8tbFSagB2r6gJoF/eAWy9wPJoDE4hVMqafTVRtYJLcFPgs8JKqumyh49H8SXIAsKKqvr/QsWgiNgPuCxxRVfcB/ohVHzYoXV34A4HbA7cFtknyjIWNStI4JhCrLAd2HereBW+dblCSbE5LHj5ZVZ9b6Hg07/YGHpdkGa0K4sOTfGJhQ9I8Wg4sr6rBncPjaAmFNhx/Cvyqqi6uqmuBzwEPWuCYNP8uSrITQPe9YoHj0RyYQKxyCrB7ktsnuQntwa0TFjgmzZMkodWdPrOq3rnQ8Wj+VdUrq2qXqlpC+/1+vaq8ermBqKoLgfOS7NH12g84YwFD0vz7NfDAJFt3x+z98EH5DdEJwMHd3wcDxy9gLJqjRfUm6oVUVdcleRHwVVrLDx+pqp8ucFiaP3sDzwR+kuSHXb9XdW8/l7R++Bvgk91Fnl8Cz1rgeDSPquq7SY4DTqO1nPcDfGvxei3JMcC+wK2SLAdeB/wT8Okkz6EljU9ZuAg1V76JWpIkSVJvVmGSJEmS1JsJhCRJkqTeTCAkSZIk9WYCIUmSJKk3EwhJkiRJvZlASJJ6SXJykkeO9HtJkvdPM87lk49MkrQumUBIkvo6hvaSvmEHdf0lSRsJEwhJUl/HAQck2QIgyRLgtsAPk5yU5LQkP0ly4OiISfZN8qWh7vcmOaT7+35Jvpnk+0m+mmSndbEwkqS5MYGQJPVSVb8Dvgc8qut1EPAp4ErgCVV1X+BhwDuSpM80k2wO/Cvw5Kq6H/AR4M3zHbskaf5sttABSJLWK4NqTMd3388GAvxjkn2AG4CdgR2BC3tMbw/g7sCJXc6xKXDB/IctSZovJhCSpNn4AvDOJPcFtqqq07qqSDsA96uqa5MsA7YcGe86Vr/rPRge4KdVtddkw5YkzRerMEmSequqy4GTaVWNBg9Pbwes6JKHhwG3GzPqucBdk2yRZDtgv67/WcAOSfaCVqUpyd0muQySpLXjHQhJ0mwdA3yOVS0yfRL4YpJTgR8CPxsdoarOS/Jp4MfA2cAPuv7XJHky8J4usdgMeBfw04kvhSRpTlJVCx2DJEmSpPWEVZgkSZIk9WYCIUmSJKk3EwhJkiRJvZlASJIkSerNBEKSJElSbyYQkiRJknozgZAkSZLUmwmEJEmSpN7+P/Ag74nA8BP4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 792x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log-transform the skewed features\n",
    "features_log_transformed = features_raw.apply(lambda x: np.log(x + 1))\n",
    "\n",
    "# Visualize the new log distributions\n",
    "distribution(features_log_transformed, 6, transformed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection\n",
    "Detecting outliers in the data is extremely important in the data preprocessing step of any analysis. The presence of outliers can often skew results which take into consideration these data points. There are many \"rules of thumb\" for what constitutes an outlier in a dataset. Here, we will use [Tukey's Method for identfying outliers](https://www.stat.cmu.edu/~cshalizi/statcomp/13/labs/05/lab-05.pdf): An **outlier step** is calculated as 1.5 times the interquartile range (IQR). A data point with a feature that is beyond an outlier step outside of the IQR for that feature is considered abnormal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data after removing outliers: (396, 71)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta ch(1)</th>\n",
       "      <th>theta ch(1)</th>\n",
       "      <th>alpha ch(1)</th>\n",
       "      <th>beta ch(1)</th>\n",
       "      <th>gamma ch(1)</th>\n",
       "      <th>delta ch(2)</th>\n",
       "      <th>theta ch(2)</th>\n",
       "      <th>alpha ch(2)</th>\n",
       "      <th>beta ch(2)</th>\n",
       "      <th>gamma ch(2)</th>\n",
       "      <th>...</th>\n",
       "      <th>theta ch(13)</th>\n",
       "      <th>alpha ch(13)</th>\n",
       "      <th>beta ch(13)</th>\n",
       "      <th>gamma ch(13)</th>\n",
       "      <th>delta ch(14)</th>\n",
       "      <th>theta ch(14)</th>\n",
       "      <th>alpha ch(14)</th>\n",
       "      <th>beta ch(14)</th>\n",
       "      <th>gamma ch(14)</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.452951</td>\n",
       "      <td>0.250172</td>\n",
       "      <td>0.220249</td>\n",
       "      <td>0.773330</td>\n",
       "      <td>0.765025</td>\n",
       "      <td>8.172571</td>\n",
       "      <td>3.610910</td>\n",
       "      <td>2.422925</td>\n",
       "      <td>2.715961</td>\n",
       "      <td>1.830689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135474</td>\n",
       "      <td>0.091557</td>\n",
       "      <td>0.246077</td>\n",
       "      <td>0.242994</td>\n",
       "      <td>6.784328</td>\n",
       "      <td>2.918801</td>\n",
       "      <td>2.344914</td>\n",
       "      <td>2.781737</td>\n",
       "      <td>1.920093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.357138</td>\n",
       "      <td>0.213983</td>\n",
       "      <td>0.224877</td>\n",
       "      <td>0.726666</td>\n",
       "      <td>0.770034</td>\n",
       "      <td>8.596461</td>\n",
       "      <td>5.028774</td>\n",
       "      <td>2.465565</td>\n",
       "      <td>2.671486</td>\n",
       "      <td>1.874179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335027</td>\n",
       "      <td>0.089441</td>\n",
       "      <td>0.293197</td>\n",
       "      <td>0.272246</td>\n",
       "      <td>8.613326</td>\n",
       "      <td>5.027089</td>\n",
       "      <td>2.447061</td>\n",
       "      <td>2.845970</td>\n",
       "      <td>2.034099</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.341606</td>\n",
       "      <td>0.223630</td>\n",
       "      <td>0.239564</td>\n",
       "      <td>0.752748</td>\n",
       "      <td>0.772169</td>\n",
       "      <td>7.562400</td>\n",
       "      <td>3.358882</td>\n",
       "      <td>2.427457</td>\n",
       "      <td>2.616472</td>\n",
       "      <td>1.688706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081728</td>\n",
       "      <td>0.061463</td>\n",
       "      <td>0.163044</td>\n",
       "      <td>0.161699</td>\n",
       "      <td>6.452203</td>\n",
       "      <td>2.799189</td>\n",
       "      <td>2.351614</td>\n",
       "      <td>2.735219</td>\n",
       "      <td>1.868325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.435964</td>\n",
       "      <td>0.216470</td>\n",
       "      <td>0.247142</td>\n",
       "      <td>0.759808</td>\n",
       "      <td>0.786822</td>\n",
       "      <td>8.398571</td>\n",
       "      <td>4.362366</td>\n",
       "      <td>3.069902</td>\n",
       "      <td>3.025542</td>\n",
       "      <td>1.993440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137328</td>\n",
       "      <td>0.029055</td>\n",
       "      <td>0.135899</td>\n",
       "      <td>0.101088</td>\n",
       "      <td>8.346928</td>\n",
       "      <td>3.852781</td>\n",
       "      <td>2.861287</td>\n",
       "      <td>2.907571</td>\n",
       "      <td>2.075738</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.153679</td>\n",
       "      <td>0.302826</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.724298</td>\n",
       "      <td>0.767031</td>\n",
       "      <td>5.202555</td>\n",
       "      <td>3.250537</td>\n",
       "      <td>2.239578</td>\n",
       "      <td>2.528191</td>\n",
       "      <td>1.698087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055831</td>\n",
       "      <td>0.036041</td>\n",
       "      <td>0.100365</td>\n",
       "      <td>0.099231</td>\n",
       "      <td>4.377709</td>\n",
       "      <td>2.785592</td>\n",
       "      <td>2.368885</td>\n",
       "      <td>2.669377</td>\n",
       "      <td>1.766060</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.243399</td>\n",
       "      <td>0.416432</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.716920</td>\n",
       "      <td>0.609165</td>\n",
       "      <td>4.611930</td>\n",
       "      <td>3.181279</td>\n",
       "      <td>2.119651</td>\n",
       "      <td>2.403115</td>\n",
       "      <td>1.596151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.062337</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.184293</td>\n",
       "      <td>4.308840</td>\n",
       "      <td>2.709964</td>\n",
       "      <td>2.282973</td>\n",
       "      <td>2.621324</td>\n",
       "      <td>1.751905</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.231168</td>\n",
       "      <td>0.416768</td>\n",
       "      <td>0.234074</td>\n",
       "      <td>0.757738</td>\n",
       "      <td>0.604992</td>\n",
       "      <td>4.560934</td>\n",
       "      <td>3.450720</td>\n",
       "      <td>2.204463</td>\n",
       "      <td>2.457886</td>\n",
       "      <td>1.612568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094610</td>\n",
       "      <td>0.064218</td>\n",
       "      <td>0.209050</td>\n",
       "      <td>0.183974</td>\n",
       "      <td>4.274626</td>\n",
       "      <td>2.750143</td>\n",
       "      <td>2.150309</td>\n",
       "      <td>2.540910</td>\n",
       "      <td>1.696993</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.319035</td>\n",
       "      <td>0.132891</td>\n",
       "      <td>0.110695</td>\n",
       "      <td>0.269885</td>\n",
       "      <td>0.161230</td>\n",
       "      <td>7.217653</td>\n",
       "      <td>3.265109</td>\n",
       "      <td>2.175213</td>\n",
       "      <td>2.556429</td>\n",
       "      <td>1.651229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033715</td>\n",
       "      <td>0.021577</td>\n",
       "      <td>0.048882</td>\n",
       "      <td>0.049247</td>\n",
       "      <td>7.651503</td>\n",
       "      <td>2.883918</td>\n",
       "      <td>2.233456</td>\n",
       "      <td>2.616125</td>\n",
       "      <td>1.719394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.359671</td>\n",
       "      <td>0.212949</td>\n",
       "      <td>0.133650</td>\n",
       "      <td>0.290370</td>\n",
       "      <td>0.162559</td>\n",
       "      <td>7.326955</td>\n",
       "      <td>2.975198</td>\n",
       "      <td>2.381263</td>\n",
       "      <td>2.645452</td>\n",
       "      <td>1.642183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032390</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>0.052999</td>\n",
       "      <td>0.036384</td>\n",
       "      <td>7.384579</td>\n",
       "      <td>2.846160</td>\n",
       "      <td>2.271259</td>\n",
       "      <td>2.627694</td>\n",
       "      <td>1.595041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.314252</td>\n",
       "      <td>0.189369</td>\n",
       "      <td>0.157402</td>\n",
       "      <td>0.383091</td>\n",
       "      <td>0.254917</td>\n",
       "      <td>7.488508</td>\n",
       "      <td>3.129113</td>\n",
       "      <td>2.125692</td>\n",
       "      <td>2.609765</td>\n",
       "      <td>1.700369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030990</td>\n",
       "      <td>0.018014</td>\n",
       "      <td>0.057290</td>\n",
       "      <td>0.053625</td>\n",
       "      <td>7.450604</td>\n",
       "      <td>2.786484</td>\n",
       "      <td>2.284117</td>\n",
       "      <td>2.668754</td>\n",
       "      <td>1.770094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    delta ch(1)  theta ch(1)  alpha ch(1)  beta ch(1)  gamma ch(1)  \\\n",
       "0      0.452951     0.250172     0.220249    0.773330     0.765025   \n",
       "1      0.357138     0.213983     0.224877    0.726666     0.770034   \n",
       "2      0.341606     0.223630     0.239564    0.752748     0.772169   \n",
       "3      0.435964     0.216470     0.247142    0.759808     0.786822   \n",
       "8      0.153679     0.302826     0.195122    0.724298     0.767031   \n",
       "11     0.243399     0.416432     0.246914    0.716920     0.609165   \n",
       "14     0.231168     0.416768     0.234074    0.757738     0.604992   \n",
       "15     0.319035     0.132891     0.110695    0.269885     0.161230   \n",
       "16     0.359671     0.212949     0.133650    0.290370     0.162559   \n",
       "17     0.314252     0.189369     0.157402    0.383091     0.254917   \n",
       "\n",
       "    delta ch(2)  theta ch(2)  alpha ch(2)  beta ch(2)  gamma ch(2)  ...  \\\n",
       "0      8.172571     3.610910     2.422925    2.715961     1.830689  ...   \n",
       "1      8.596461     5.028774     2.465565    2.671486     1.874179  ...   \n",
       "2      7.562400     3.358882     2.427457    2.616472     1.688706  ...   \n",
       "3      8.398571     4.362366     3.069902    3.025542     1.993440  ...   \n",
       "8      5.202555     3.250537     2.239578    2.528191     1.698087  ...   \n",
       "11     4.611930     3.181279     2.119651    2.403115     1.596151  ...   \n",
       "14     4.560934     3.450720     2.204463    2.457886     1.612568  ...   \n",
       "15     7.217653     3.265109     2.175213    2.556429     1.651229  ...   \n",
       "16     7.326955     2.975198     2.381263    2.645452     1.642183  ...   \n",
       "17     7.488508     3.129113     2.125692    2.609765     1.700369  ...   \n",
       "\n",
       "    theta ch(13)  alpha ch(13)  beta ch(13)  gamma ch(13)  delta ch(14)  \\\n",
       "0       0.135474      0.091557     0.246077      0.242994      6.784328   \n",
       "1       0.335027      0.089441     0.293197      0.272246      8.613326   \n",
       "2       0.081728      0.061463     0.163044      0.161699      6.452203   \n",
       "3       0.137328      0.029055     0.135899      0.101088      8.346928   \n",
       "8       0.055831      0.036041     0.100365      0.099231      4.377709   \n",
       "11      0.096360      0.062337     0.223881      0.184293      4.308840   \n",
       "14      0.094610      0.064218     0.209050      0.183974      4.274626   \n",
       "15      0.033715      0.021577     0.048882      0.049247      7.651503   \n",
       "16      0.032390      0.015388     0.052999      0.036384      7.384579   \n",
       "17      0.030990      0.018014     0.057290      0.053625      7.450604   \n",
       "\n",
       "    theta ch(14)  alpha ch(14)  beta ch(14)  gamma ch(14)  state  \n",
       "0       2.918801      2.344914     2.781737      1.920093      1  \n",
       "1       5.027089      2.447061     2.845970      2.034099      1  \n",
       "2       2.799189      2.351614     2.735219      1.868325      1  \n",
       "3       3.852781      2.861287     2.907571      2.075738      1  \n",
       "8       2.785592      2.368885     2.669377      1.766060      2  \n",
       "11      2.709964      2.282973     2.621324      1.751905      3  \n",
       "14      2.750143      2.150309     2.540910      1.696993      3  \n",
       "15      2.883918      2.233456     2.616125      1.719394      1  \n",
       "16      2.846160      2.271259     2.627694      1.595041      1  \n",
       "17      2.786484      2.284117     2.668754      1.770094      1  \n",
       "\n",
       "[10 rows x 71 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate Q1 (25th quantile of the data) for all features.\n",
    "Q1 = features_log_transformed.quantile(0.25)\n",
    "\n",
    "# Calculate Q3 (90th quantile of the data) for all features.\n",
    "Q3 = features_log_transformed.quantile(0.90)\n",
    "\n",
    "# Use the interquartile range to calculate an outlier step (1.5 times the interquartile range).\n",
    "IQR = Q3 - Q1\n",
    "step = 1.5 * IQR\n",
    "\n",
    "# Remove the outliers from the dataset.\n",
    "features_log_transformed_out = features_log_transformed[~((features_log_transformed < (Q1 - step)) |(features_log_transformed > (Q3 + step))).any(axis=1)]\n",
    "\n",
    "# Join the features and the target after removing outliers.\n",
    "preprocessed_data_out = features_log_transformed_out.join(target_raw)\n",
    "target_raw_out = preprocessed_data_out[preprocessed_data_out.columns[-1]]\n",
    "\n",
    "# Print data shape after removing outliers.\n",
    "print(\"The shape of the data after removing outliers: {}\".format(preprocessed_data_out.shape))\n",
    "\n",
    "# Success - Display the first ten records\n",
    "display(preprocessed_data_out.head(n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Numerical Features\n",
    "In addition to performing transformations on features that are highly skewed, it is often good practice to perform some type of scaling on numerical features. Applying a scaling to the data does not change the shape of each feature's distribution (such as `'delta ch(2)'` above); however, normalization ensures that each feature is treated equally when applying supervised learners. Note that once scaling is applied, observing the data in its raw form will no longer have the same original meaning, as exampled below.\n",
    "\n",
    "Run the code cell below to normalize each numerical feature. We will use [`sklearn.preprocessing.MinMaxScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta ch(1)</th>\n",
       "      <th>theta ch(1)</th>\n",
       "      <th>alpha ch(1)</th>\n",
       "      <th>beta ch(1)</th>\n",
       "      <th>gamma ch(1)</th>\n",
       "      <th>delta ch(2)</th>\n",
       "      <th>theta ch(2)</th>\n",
       "      <th>alpha ch(2)</th>\n",
       "      <th>beta ch(2)</th>\n",
       "      <th>gamma ch(2)</th>\n",
       "      <th>...</th>\n",
       "      <th>delta ch(13)</th>\n",
       "      <th>theta ch(13)</th>\n",
       "      <th>alpha ch(13)</th>\n",
       "      <th>beta ch(13)</th>\n",
       "      <th>gamma ch(13)</th>\n",
       "      <th>delta ch(14)</th>\n",
       "      <th>theta ch(14)</th>\n",
       "      <th>alpha ch(14)</th>\n",
       "      <th>beta ch(14)</th>\n",
       "      <th>gamma ch(14)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.122683</td>\n",
       "      <td>0.100524</td>\n",
       "      <td>0.134160</td>\n",
       "      <td>0.433059</td>\n",
       "      <td>0.520178</td>\n",
       "      <td>0.925529</td>\n",
       "      <td>0.530846</td>\n",
       "      <td>0.214469</td>\n",
       "      <td>0.429813</td>\n",
       "      <td>0.625276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297717</td>\n",
       "      <td>0.236651</td>\n",
       "      <td>0.190770</td>\n",
       "      <td>0.213827</td>\n",
       "      <td>0.235725</td>\n",
       "      <td>0.677290</td>\n",
       "      <td>0.363328</td>\n",
       "      <td>0.238914</td>\n",
       "      <td>0.441711</td>\n",
       "      <td>0.626872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088784</td>\n",
       "      <td>0.074159</td>\n",
       "      <td>0.138888</td>\n",
       "      <td>0.402480</td>\n",
       "      <td>0.523890</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950541</td>\n",
       "      <td>0.224466</td>\n",
       "      <td>0.415325</td>\n",
       "      <td>0.650494</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586360</td>\n",
       "      <td>0.186340</td>\n",
       "      <td>0.254861</td>\n",
       "      <td>0.264148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.268183</td>\n",
       "      <td>0.466433</td>\n",
       "      <td>0.692629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.083289</td>\n",
       "      <td>0.081187</td>\n",
       "      <td>0.153891</td>\n",
       "      <td>0.419571</td>\n",
       "      <td>0.525472</td>\n",
       "      <td>0.818331</td>\n",
       "      <td>0.456244</td>\n",
       "      <td>0.215531</td>\n",
       "      <td>0.397403</td>\n",
       "      <td>0.542946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219069</td>\n",
       "      <td>0.142463</td>\n",
       "      <td>0.127787</td>\n",
       "      <td>0.141519</td>\n",
       "      <td>0.156735</td>\n",
       "      <td>0.618690</td>\n",
       "      <td>0.327207</td>\n",
       "      <td>0.240834</td>\n",
       "      <td>0.423807</td>\n",
       "      <td>0.597013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.116673</td>\n",
       "      <td>0.075970</td>\n",
       "      <td>0.161633</td>\n",
       "      <td>0.424198</td>\n",
       "      <td>0.536330</td>\n",
       "      <td>0.965234</td>\n",
       "      <td>0.753281</td>\n",
       "      <td>0.366153</td>\n",
       "      <td>0.530663</td>\n",
       "      <td>0.719648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730742</td>\n",
       "      <td>0.239900</td>\n",
       "      <td>0.059965</td>\n",
       "      <td>0.117880</td>\n",
       "      <td>0.097841</td>\n",
       "      <td>0.952996</td>\n",
       "      <td>0.645376</td>\n",
       "      <td>0.386874</td>\n",
       "      <td>0.490141</td>\n",
       "      <td>0.716646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.138885</td>\n",
       "      <td>0.108491</td>\n",
       "      <td>0.400929</td>\n",
       "      <td>0.521665</td>\n",
       "      <td>0.403742</td>\n",
       "      <td>0.424173</td>\n",
       "      <td>0.171483</td>\n",
       "      <td>0.368644</td>\n",
       "      <td>0.548386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150208</td>\n",
       "      <td>0.097079</td>\n",
       "      <td>0.074585</td>\n",
       "      <td>0.086937</td>\n",
       "      <td>0.096037</td>\n",
       "      <td>0.252664</td>\n",
       "      <td>0.323101</td>\n",
       "      <td>0.245783</td>\n",
       "      <td>0.398466</td>\n",
       "      <td>0.538028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   delta ch(1)  theta ch(1)  alpha ch(1)  beta ch(1)  gamma ch(1)  \\\n",
       "0     0.122683     0.100524     0.134160    0.433059     0.520178   \n",
       "1     0.088784     0.074159     0.138888    0.402480     0.523890   \n",
       "2     0.083289     0.081187     0.153891    0.419571     0.525472   \n",
       "3     0.116673     0.075970     0.161633    0.424198     0.536330   \n",
       "4     0.016800     0.138885     0.108491    0.400929     0.521665   \n",
       "\n",
       "   delta ch(2)  theta ch(2)  alpha ch(2)  beta ch(2)  gamma ch(2)  ...  \\\n",
       "0     0.925529     0.530846     0.214469    0.429813     0.625276  ...   \n",
       "1     1.000000     0.950541     0.224466    0.415325     0.650494  ...   \n",
       "2     0.818331     0.456244     0.215531    0.397403     0.542946  ...   \n",
       "3     0.965234     0.753281     0.366153    0.530663     0.719648  ...   \n",
       "4     0.403742     0.424173     0.171483    0.368644     0.548386  ...   \n",
       "\n",
       "   delta ch(13)  theta ch(13)  alpha ch(13)  beta ch(13)  gamma ch(13)  \\\n",
       "0      0.297717      0.236651      0.190770     0.213827      0.235725   \n",
       "1      1.000000      0.586360      0.186340     0.254861      0.264148   \n",
       "2      0.219069      0.142463      0.127787     0.141519      0.156735   \n",
       "3      0.730742      0.239900      0.059965     0.117880      0.097841   \n",
       "4      0.150208      0.097079      0.074585     0.086937      0.096037   \n",
       "\n",
       "   delta ch(14)  theta ch(14)  alpha ch(14)  beta ch(14)  gamma ch(14)  \n",
       "0      0.677290      0.363328      0.238914     0.441711      0.626872  \n",
       "1      1.000000      1.000000      0.268183     0.466433      0.692629  \n",
       "2      0.618690      0.327207      0.240834     0.423807      0.597013  \n",
       "3      0.952996      0.645376      0.386874     0.490141      0.716646  \n",
       "4      0.252664      0.323101      0.245783     0.398466      0.538028  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "\n",
    "features_log_minmax_transform_out = pd.DataFrame(scaler.fit_transform(features_log_transformed_out), columns=features_raw.columns)\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "display(features_log_minmax_transform_out.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Developing a Model\n",
    "In this section of the project, we will develop the tools and techniques necessary for a model to make a prediction. Being able to make accurate evaluations of each model's performance through the use of these tools and techniques helps to greatly reinforce the confidence in the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and Split Data\n",
    "Now that the data has been scaled to a more normal distribution and has had any necessary outliers removed. As always, we will now split the data (both features and their labels) into training and test sets. 80% of the data will be used for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing split was successful.\n"
     ]
    }
   ],
   "source": [
    "# Import 'train_test_split'\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assign the features to the variable Bands, and the labels to the variable state.\n",
    "Bands = np.array(features_log_minmax_transform_out)\n",
    "state = np.array(target_raw_out)\n",
    "\n",
    "# Shuffle and split the data into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(Bands, state, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Success\n",
    "print(\"Training and testing split was successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Transformation\n",
    "\n",
    "We can now apply PCA to the data for dimensionality reduction, to fit the relatively small size of the data compared to its features number, and also to discover which dimensions about the data best maximize the variance of features involved. In addition to finding these dimensions, PCA will also report the *explained variance ratio* of each dimension — how much variance within the data is explained by that dimension alone. Note that a component (dimension) from PCA can be considered a new \"feature\" of the space, however it is a composition of the original features present in the data.\n",
    "\n",
    "In the next code cell, we will plot the Cumulative Summation of the Explained Variance, to help us decide the number of principal components to be used in the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Fitting the PCA algorithm with our Data\n",
    "pca = PCA().fit(X_train)\n",
    "\n",
    "# Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure(figsize = (14,7))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Pulsar Dataset Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot tells us that selecting **33** components we can preserve something around 97% or 98% of the total variance of the data. It makes sense, we’ll not use 100% of our variance, because it denotes all components, and we want only the principal ones.\n",
    "\n",
    "With this information in our hands, we can implement the PCA for **33** best components by using the next snippet of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 33 eigenfaces from 316 faces\n",
      "Explained variance ratios: [18.13438172 15.77876048 12.39420029  9.29099567  6.26499169  5.43190718\n",
      "  4.52436489  4.41634351  3.35939466  2.51632471  2.28796606  1.90266741\n",
      "  1.67373601  1.4348223   1.22220207  1.07383505  0.9413552   0.73090361\n",
      "  0.69635085  0.66945919  0.55251081  0.53324383  0.42770505  0.38145065\n",
      "  0.34121742  0.27152868  0.23843399  0.22141189  0.19682605  0.17638858\n",
      "  0.16394574  0.15687332  0.14191673]\n",
      "done in 0.018s\n"
     ]
    }
   ],
   "source": [
    "# Import time\n",
    "from time import time\n",
    "\n",
    "# From the Explained Variance graph.\n",
    "n_components = 33\n",
    "\n",
    "print( \"Extracting the top %d eigenfaces from %d faces\" % (n_components, X_train.shape[0]) )\n",
    "t0 = time()\n",
    "\n",
    "# Create an instance of PCA, initializing with n_components=n_components and whiten=True\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Pass the training dataset (X_train) to pca's 'fit()' method\n",
    "pca = pca.fit(X_train)\n",
    "\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(\"Explained variance ratios:\", pca.explained_variance_ratio_*100)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting The Model\n",
    "Our final implementation requires that we bring everything together and train a model using the **support vector machine algorithm**. To ensure that we are producing an optimized model, we will train the model using the grid search technique to optimize the `'gamma'` and `'C'` parameters for the **svm classifier**.\n",
    "\n",
    "In addition, the implementation is using `ShuffleSplit()` for an alternative form of cross-validation (see the `'cv_sets'` variable). While it is not the K-Fold cross-validation technique, this type of cross-validation technique is just as useful!. The `ShuffleSplit()` implementation will create 10 (`'n_splits'`) shuffled sets, and for each shuffle, 20% (`'test_size'`) of the data will be used as the *validation set*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 'gamma' is 0.1 for the optimal model.\n",
      "Parameter 'C' is 1000.0 for the optimal model.\n"
     ]
    }
   ],
   "source": [
    "# Fit the training data to the model using grid search\n",
    "model = fit_model(X_train_pca, y_train)\n",
    "\n",
    "# Produce the value for 'gamma' and 'C'\n",
    "print(\"Parameter 'gamma' is {} for the optimal model.\".format(model.get_params()['gamma']))\n",
    "print(\"Parameter 'C' is {} for the optimal model.\".format(model.get_params()['C']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions\n",
    "Once the model has been trained on a given set of data, it can now be used to make predictions on new sets of input data. In the case of a **support vector machine**, the model has learned **how the frequency bands values relate to the mental state of the driver**, and can respond with a detection of the current **mental state**. We can use these predictions to gain information about data where the value of the target variable is unknown — such as data the model was not trained on (i.e testing data or future readings of the driver's brain signals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted mental state for test 1's bands: Drowsy\n",
      "Predicted mental state for test 2's bands: De-Focused\n",
      "Predicted mental state for test 3's bands: De-Focused\n",
      "Predicted mental state for test 4's bands: Focused\n",
      "Predicted mental state for test 5's bands: Drowsy\n",
      "Predicted mental state for test 6's bands: Focused\n",
      "Predicted mental state for test 7's bands: De-Focused\n",
      "Predicted mental state for test 8's bands: De-Focused\n",
      "Predicted mental state for test 9's bands: De-Focused\n",
      "Predicted mental state for test 10's bands: Drowsy\n",
      "Predicted mental state for test 11's bands: Focused\n",
      "Predicted mental state for test 12's bands: Drowsy\n",
      "Predicted mental state for test 13's bands: Drowsy\n",
      "Predicted mental state for test 14's bands: De-Focused\n",
      "Predicted mental state for test 15's bands: Drowsy\n",
      "Predicted mental state for test 16's bands: Focused\n",
      "Predicted mental state for test 17's bands: De-Focused\n",
      "Predicted mental state for test 18's bands: Drowsy\n",
      "Predicted mental state for test 19's bands: De-Focused\n",
      "Predicted mental state for test 20's bands: Drowsy\n",
      "Predicted mental state for test 21's bands: De-Focused\n",
      "Predicted mental state for test 22's bands: Drowsy\n",
      "Predicted mental state for test 23's bands: Focused\n",
      "Predicted mental state for test 24's bands: Focused\n",
      "Predicted mental state for test 25's bands: Drowsy\n",
      "Predicted mental state for test 26's bands: De-Focused\n",
      "Predicted mental state for test 27's bands: Drowsy\n",
      "Predicted mental state for test 28's bands: Drowsy\n",
      "Predicted mental state for test 29's bands: De-Focused\n",
      "Predicted mental state for test 30's bands: Focused\n",
      "Predicted mental state for test 31's bands: Drowsy\n",
      "Predicted mental state for test 32's bands: Focused\n",
      "Predicted mental state for test 33's bands: Drowsy\n",
      "Predicted mental state for test 34's bands: De-Focused\n",
      "Predicted mental state for test 35's bands: Focused\n",
      "Predicted mental state for test 36's bands: Focused\n",
      "Predicted mental state for test 37's bands: De-Focused\n",
      "Predicted mental state for test 38's bands: De-Focused\n",
      "Predicted mental state for test 39's bands: De-Focused\n",
      "Predicted mental state for test 40's bands: Focused\n",
      "Predicted mental state for test 41's bands: De-Focused\n",
      "Predicted mental state for test 42's bands: Focused\n",
      "Predicted mental state for test 43's bands: Drowsy\n",
      "Predicted mental state for test 44's bands: De-Focused\n",
      "Predicted mental state for test 45's bands: De-Focused\n",
      "Predicted mental state for test 46's bands: Focused\n",
      "Predicted mental state for test 47's bands: Focused\n",
      "Predicted mental state for test 48's bands: Focused\n",
      "Predicted mental state for test 49's bands: Focused\n",
      "Predicted mental state for test 50's bands: De-Focused\n",
      "Predicted mental state for test 51's bands: Focused\n",
      "Predicted mental state for test 52's bands: Focused\n",
      "Predicted mental state for test 53's bands: De-Focused\n",
      "Predicted mental state for test 54's bands: Focused\n",
      "Predicted mental state for test 55's bands: De-Focused\n",
      "Predicted mental state for test 56's bands: Focused\n",
      "Predicted mental state for test 57's bands: Drowsy\n",
      "Predicted mental state for test 58's bands: Focused\n",
      "Predicted mental state for test 59's bands: Focused\n",
      "Predicted mental state for test 60's bands: Focused\n",
      "Predicted mental state for test 61's bands: Focused\n",
      "Predicted mental state for test 62's bands: Focused\n",
      "Predicted mental state for test 63's bands: Drowsy\n",
      "Predicted mental state for test 64's bands: Focused\n",
      "Predicted mental state for test 65's bands: Focused\n",
      "Predicted mental state for test 66's bands: Focused\n",
      "Predicted mental state for test 67's bands: Focused\n",
      "Predicted mental state for test 68's bands: Focused\n",
      "Predicted mental state for test 69's bands: Drowsy\n",
      "Predicted mental state for test 70's bands: Drowsy\n",
      "Predicted mental state for test 71's bands: De-Focused\n",
      "Predicted mental state for test 72's bands: Drowsy\n",
      "Predicted mental state for test 73's bands: Drowsy\n",
      "Predicted mental state for test 74's bands: De-Focused\n",
      "Predicted mental state for test 75's bands: De-Focused\n",
      "Predicted mental state for test 76's bands: Focused\n",
      "Predicted mental state for test 77's bands: De-Focused\n",
      "Predicted mental state for test 78's bands: Focused\n",
      "Predicted mental state for test 79's bands: Drowsy\n",
      "Predicted mental state for test 80's bands: Drowsy\n"
     ]
    }
   ],
   "source": [
    "# Make predictions. Store them in the variable y_pred.\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "# Label states class.\n",
    "states_class = ['Focused', 'De-Focused', 'Drowsy']\n",
    "\n",
    "# Show predictions\n",
    "for i, state in enumerate(y_pred):\n",
    "    print(\"Predicted mental state for test {}'s bands: {}\".format(i+1, states_class[state-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Evaluation\n",
    "In this final section, we will run some evaluation metrics to check the performance of the optimized model on the testing data.\n",
    "\n",
    "In the next code cell, we will calculate the `'F1-Score'` of the model on testing data perdictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 87.5 %\n"
     ]
    }
   ],
   "source": [
    "# Import 'f1_score'\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate the f1 score and assign it to the variable score.\n",
    "score = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "# Print score.\n",
    "print(\"F1 score: %0.1f %%\" %(score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell, to calculate the confusion matrix of the **3** state classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  1  1]\n",
      " [ 3 23  3]\n",
      " [ 1  1 19]]\n"
     ]
    }
   ],
   "source": [
    "# Import 'confusion_matrix'\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix and assign it to the variable matrix.\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the confusion matrix.\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we make a classification report to get a detailed performance evaluation, with scores for the model on each **mental state** class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.93      0.90        30\n",
      "           2       0.92      0.79      0.85        29\n",
      "           3       0.83      0.90      0.86        21\n",
      "\n",
      "   micro avg       0.88      0.88      0.88        80\n",
      "   macro avg       0.87      0.88      0.87        80\n",
      "weighted avg       0.88      0.88      0.87        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import 'classification_report'\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Calculate the classification report and assign it to the variable report.\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the classification report.\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Comment\n",
    "The model attained a testing accuracy of around **88%**, which indicates a good performance of the model that we can rely on for **mental state** detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
